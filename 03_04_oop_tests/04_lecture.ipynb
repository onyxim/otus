{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #4 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Motivation](#Motivation)\n",
    "    1. [What is testing?](#What-is-testing?)\n",
    "    2. [Why do I need it?](#Why-do-I-need-it?)\n",
    "    3. [When should I write tests?](#When-should-I-write-tests?)\n",
    "2. [Test desing](#Test-desing)\n",
    "    1. [What tests do I write? ](#What-tests-do-I-write? )\n",
    "    2. [Equivalence class partitioning](#Equivalence-class-partitioning)\n",
    "    3. [Boundary-value analysis](#Boundary-value-analysis)\n",
    "    4. [Write narrow tests](#Write-narrow-tests)\n",
    "    5. [Repeat Yourself](#Repeat-Yourself)\n",
    "3. [Testing](#Testing)\n",
    "    1. [Unit](#Unit)\n",
    "    2. [Inegration](#Inegration)\n",
    "    3. [Functional](#Functional)\n",
    "    4. [Acceptance](#Acceptance)\n",
    "    5. [Anti-patterns](#Anti-patterns)\n",
    "4. [Techniques](#Techniques)\n",
    "    1. [Mocking](#Mocking)\n",
    "    2. [Monkey patching](#Monkey-patching)\n",
    "    3. [Fixtures](#Fixtures)\n",
    "5. [Automatization](#Automatization)\n",
    "    1. [Continuous Integration](#Continuous-Integration)\n",
    "    2. [Continuous Delivery](#Continuous-Delivery)\n",
    "    3. [Continuous Deployment](#Continuous-Deployment)\n",
    "6. [Best practices](#Best-practices)\n",
    "    1. [Feature flags](#Feature-flags)\n",
    "    2. [Canary deployment](#Canary-deployment)\n",
    "    3. [Staged rollouts](#Staged-rollouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing is learning more about the application or system under test. This includes, but is definitely not limited to, checking that it responds as you expect to various inputs and environments. There is a tendency among programmers to view testing as a bottom-up checking mechanism. A sort of correctness filter you can pass your software through at various levels to ensure it’s doing what you want it to do. \n",
    "\n",
    "You could compare testing to being a scientist. When faced with a new application or system you have some information about what it’s supposed to do and if you’re very lucky, an idea about how it should do it. Treat this as the hypothesis under test, and null hypothesis is that everything is broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Why do I need it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing is confidence, it’s a way to make sure you’re doing what you should be doing. It’s information, it tells you about how your software works. It’s ease of writing, if you’re refactoring, or doing TDD, you’ll find that your tests tell you exactly what you should be accepting and pushing out, and break it down into conceptualisable chunks. If you can’t conceptualise it, you’ve not broken it down far enough, test each step and you’ll get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When should I write tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the time.\n",
    "\n",
    "Test the design, test the components, test your functions, test your whole system. When you notice a bug, write a test for it, then fix the bug. Write more tests around that area, fix the bugs those expose. Testing should be as much a part of development as anything else. Every now and then, just stop writing and explore what you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test desing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What tests do I write? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " square_root_bi(4, 0.0001)\n",
      "Bi method.  Num. iterations: 1 Estimate: 2.0\n",
      "2.0\n",
      " square_root_bi(9, 0.0001)\n",
      "Bi method.  Num. iterations: 18 Estimate: 2.99998855591\n",
      "2.99998855591\n",
      " square_root_bi(2, 0.0001)\n",
      "Bi method.  Num. iterations: 14 Estimate: 1.41418457031\n",
      "1.41418457031\n",
      " square_root_bi(0.25, 0.0001)\n",
      "Bi method.  Num. iterations: 1 Estimate: 0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def square_root_bi(x, epsilon):\n",
    "    \"\"\"Return y s.t. y*y is within epsilon of x\"\"\"\n",
    "    assert x >= 0, 'x must be non-negative, not ' + str(x)\n",
    "    assert epsilon > 0, 'epsilon must be postive, not ' + str(epsilon)\n",
    "    low = 0\n",
    "    high = max(x, 1.0)\n",
    "    guess = (low + high) / 2.0\n",
    "    ctr = 1\n",
    "    max_ctr = 1000\n",
    "    while abs(guess**2 - x) > epsilon and ctr <= max_ctr:\n",
    "        if guess**2 < x:\n",
    "            low = guess\n",
    "        else:\n",
    "            high = guess\n",
    "        guess = (low + high) / 2.0\n",
    "        ctr += 1\n",
    "    assert ctr <= max_ctr, 'Iteration count exceeded'\n",
    "    print 'Bi method.  Num. iterations:', ctr, 'Estimate:', guess\n",
    "    return guess\n",
    "\n",
    "# square_root_bi(0.25, 0.001)\n",
    "\n",
    "\n",
    "def test_bi():\n",
    "    print \" square_root_bi(4, 0.0001)\"\n",
    "    print square_root_bi(4, 0.0001)\n",
    "\n",
    "    print \" square_root_bi(9, 0.0001)\"\n",
    "    print square_root_bi(9, 0.0001)\n",
    "\n",
    "    print \" square_root_bi(2, 0.0001)\"\n",
    "    print square_root_bi(2, 0.0001)\n",
    "\n",
    "    print \" square_root_bi(0.25, 0.0001)\"\n",
    "    print square_root_bi(0.25, 0.0001)\n",
    "\n",
    "test_bi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def test_bi_unsigned_int():\n",
    "    for i in xrange(2**32):\n",
    "        expected_sqrt = math.sqrt(i)\n",
    "        sqrt = square_root_bi(i, 0.0001)\n",
    "        diff = abs(sqrt - expected_sqrt)\n",
    "        assert diff < 0.01, diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is __minimum__ number of tests with __maximum__ coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalence class partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECP divides the input data of a software unit into partitions of equivalent data from which test cases can be derived. In principle, test cases are designed to cover each partition at least once. This technique tries to define test cases that uncover classes of errors, thereby reducing the total number of test cases that must be developed. An advantage of this approach is reduction in the time required for testing a software due to lesser number of test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score2mark(score):\n",
    "    if 0 <= score <= 59:\n",
    "        return 2\n",
    "    elif 60 <= score <= 74:\n",
    "        return 3\n",
    "    elif 75 <= score <= 89:\n",
    "        return 4\n",
    "    elif 90 <= score <= 100:\n",
    "        return 5\n",
    "    raise ValueError(\"Invalid score %s\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalence classes:\n",
    "* [0; 59],\n",
    "* [60; 74],\n",
    "* [75; 89],\n",
    "* [90; 100],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mark_valid_score():\n",
    "    score_to_expected_mark = {\n",
    "        40: 2,\n",
    "        65: 3,\n",
    "        80: 4,\n",
    "        95: 5,\n",
    "    }\n",
    "    for s, m in score_to_expected_mark.items():\n",
    "        returned_mark = score2mark(s)\n",
    "        assert returned_mark == m, \"Mark for score %s is %s, but %s expected\" % (s, returned_mark, m)\n",
    "\n",
    "test_mark_valid_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just because two items/values are suppose to be in the same class and behave the same, does not mean they DO behave the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boundary-value analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bar](https://pbs.twimg.com/media/CS3Rp2TUwAIyRrE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary value analysis is a software testing technique in which tests are designed to include representatives of boundary values in a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mark_invalid_score():\n",
    "    for s in (-1, 101, 2**64, \"\"):\n",
    "        try:\n",
    "            m = score2mark(s)\n",
    "        except Exception, e:\n",
    "            assert isinstance(e, ValueError), \"Unexpected error: %s: %s\" % (type(e), e)\n",
    "        else:\n",
    "            raise AssertionError(\"No error for bad value: score2mark(%s) -> %s\" % (s, m))\n",
    "\n",
    "def test_mark_float_score():\n",
    "    s = 3.14\n",
    "    expected_mark = 2\n",
    "    m = score2mark(s)\n",
    "    assert m == expected_mark, \"Mark for score %s is %s, but %s expected\" % (s, m, expected_mark)\n",
    "\n",
    "    \n",
    "test_mark_invalid_score()\n",
    "test_marks_float_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real world use cases:\n",
    "* spacecraft metric systems\n",
    "* radiation therapy\n",
    "* Knight Capital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write narrow tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AccountsApiTestCase(TestCase):\n",
    "    def setUp(self):\n",
    "        super(AccountsApiTestCase, self).setUp()\n",
    "        self.user.access_api_v2 = True\n",
    "        self.user.save()\n",
    "\n",
    "    def test_api_access(self):\n",
    "        response = self.client.get(reverse('user-api'))\n",
    "        self.assertEqual(response.status_code, OK)\n",
    "\n",
    "        self.user.access_api_v2 = False\n",
    "        self.user.save()\n",
    "        response = self.client.get(reverse('user-api'))\n",
    "        self.assertEqual(response.status_code, FORBIDDEN)\n",
    "\n",
    "    def test_create_token(self):\n",
    "        self.make_user_not_admin(self.user)\n",
    "        # при первом заходе генерится ключ доступа\n",
    "        self.client.get(reverse('user-api'))\n",
    "        api_key = ApiKey.objects.get(user=self.user, is_blocked=False)\n",
    "        self.assertEqual(api_key.allowed_ips, [])\n",
    "        self.assertEqual(api_key.expired, None)\n",
    "\n",
    "        # при втором заходе уже не генерится\n",
    "        self.client.get(reverse('user-api'))\n",
    "        self.assertEqual(ApiKey.objects.filter(user=self.user).count(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flavors/tests/test_api.py\n",
    "import json\n",
    "\n",
    "from django.test import TestCase\n",
    "from django.urls import reverse\n",
    "\n",
    "from flavors.models import Flavor\n",
    "\n",
    "class DjangoRestFrameworkTests(TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        Flavor.objects.get_or_create(title='title1', slug='slug1')\n",
    "        Flavor.objects.get_or_create(title='title2', slug='slug2')\n",
    "\n",
    "        self.create_read_url = reverse('flavor_rest_api')\n",
    "        self.read_update_delete_url = \\\n",
    "            reverse('flavor_rest_api', kwargs={'slug': 'slug1'})\n",
    "\n",
    "    def test_list(self):\n",
    "        response = self.client.get(self.create_read_url)\n",
    "\n",
    "        # Are both titles in the content?\n",
    "        self.assertContains(response, 'title1')\n",
    "        self.assertContains(response, 'title2')\n",
    "\n",
    "    def test_detail(self):\n",
    "        response = self.client.get(self.read_update_delete_url)\n",
    "        data = json.loads(response.content)\n",
    "        content = {'id': 1, 'title': 'title1', 'slug': 'slug1',\n",
    "                                            'scoops_remaining': 0}\n",
    "        self.assertEquals(data, content)\n",
    "\n",
    "    def test_create(self):\n",
    "        post = {'title': 'title3', 'slug': 'slug3'}\n",
    "        response = self.client.post(self.create_read_url, post)\n",
    "        data = json.loads(response.content)\n",
    "        self.assertEquals(response.status_code, 201)\n",
    "        content = {'id': 3, 'title': 'title3', 'slug': 'slug3',\n",
    "                                            'scoops_remaining': 0}\n",
    "        self.assertEquals(data, content)\n",
    "        self.assertEquals(Flavor.objects.count(), 3)\n",
    "\n",
    "    def test_delete(self):\n",
    "        response = self.client.delete(self.read_update_delete_url)\n",
    "        self.assertEquals(response.status_code, 204)\n",
    "        self.assertEquals(Flavor.objects.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def assertSuccess(self, response):\n",
    "        status, data = self.get_parsed_json(response)\n",
    "        self.assertTrue(status, data)\n",
    "\n",
    "    def assertForbiddenGet(self, url):\n",
    "        response = self.api_client.get(url)\n",
    "        status, data = self.get_parsed_json(response)\n",
    "        self.assertFalse(status)\n",
    "        self.assertError(response, api_errors.FORBIDDEN)\n",
    "\n",
    "    def assertForbiddenPost(self, url, post_data):\n",
    "        response = self.api_client.post(url, json.dumps(post_data))\n",
    "        status, data = self.get_parsed_json(response)\n",
    "        self.assertFalse(status)\n",
    "        self.assertError(response, api_errors.FORBIDDEN)\n",
    "\n",
    "    def assertAllowedGet(self, url):\n",
    "        response = self.api_client.get(url)\n",
    "        status, data = self.get_parsed_json(response)\n",
    "        self.assertTrue(status, data)\n",
    "\n",
    "    def assertAllowedPost(self, url, post_data):\n",
    "        response = self.api_client.post(url, json.dumps(post_data))\n",
    "        status, data = self.get_parsed_json(response)\n",
    "        self.assertTrue(status, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial anti-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_question(question_text, days):\n",
    "    \"\"\"\n",
    "    Create a question with the given `question_text` and published the\n",
    "    given number of `days` offset to now (negative for questions published\n",
    "    in the past, positive for questions that have yet to be published).\n",
    "    \"\"\"\n",
    "    time = timezone.now() + datetime.timedelta(days=days)\n",
    "    return Question.objects.create(question_text=question_text, pub_date=time)\n",
    "\n",
    "\n",
    "class QuestionIndexViewTests(TestCase):\n",
    "    def test_no_questions(self):\n",
    "        \"\"\"\n",
    "        If no questions exist, an appropriate message is displayed.\n",
    "        \"\"\"\n",
    "        response = self.client.get(reverse('polls:index'))\n",
    "        self.assertEqual(response.status_code, 200)\n",
    "        self.assertContains(response, \"No polls are available.\")\n",
    "        self.assertQuerysetEqual(response.context['latest_question_list'], [])\n",
    "\n",
    "    def test_past_question(self):\n",
    "        \"\"\"\n",
    "        Questions with a pub_date in the past are displayed on the\n",
    "        index page.\n",
    "        \"\"\"\n",
    "        create_question(question_text=\"Past question.\", days=-30)\n",
    "        response = self.client.get(reverse('polls:index'))\n",
    "        self.assertQuerysetEqual(\n",
    "            response.context['latest_question_list'],\n",
    "            ['<Question: Past question.>']\n",
    "        )\n",
    "\n",
    "    def test_future_question(self):\n",
    "        \"\"\"\n",
    "        Questions with a pub_date in the future aren't displayed on\n",
    "        the index page.\n",
    "        \"\"\"\n",
    "        create_question(question_text=\"Future question.\", days=30)\n",
    "        response = self.client.get(reverse('polls:index'))\n",
    "        self.assertContains(response, \"No polls are available.\")\n",
    "        self.assertQuerysetEqual(response.context['latest_question_list'], [])\n",
    "\n",
    "    def test_future_question_and_past_question(self):\n",
    "        \"\"\"\n",
    "        Even if both past and future questions exist, only past questions\n",
    "        are displayed.\n",
    "        \"\"\"\n",
    "        create_question(question_text=\"Past question.\", days=-30)\n",
    "        create_question(question_text=\"Future question.\", days=30)\n",
    "        response = self.client.get(reverse('polls:index'))\n",
    "        self.assertQuerysetEqual(\n",
    "            response.context['latest_question_list'],\n",
    "            ['<Question: Past question.>']\n",
    "        )\n",
    "\n",
    "    def test_two_past_questions(self):\n",
    "        \"\"\"\n",
    "        The questions index page may display multiple questions.\n",
    "        \"\"\"\n",
    "        create_question(question_text=\"Past question 1.\", days=-30)\n",
    "        create_question(question_text=\"Past question 2.\", days=-5)\n",
    "        response = self.client.get(reverse('polls:index'))\n",
    "        self.assertQuerysetEqual(\n",
    "            response.context['latest_question_list'],\n",
    "            ['<Question: Past question 2.>', '<Question: Past question 1.>']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test failures and edge cases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBStorageTestCase(TestCase):\n",
    "    def setUp(self):\n",
    "        super(RBStorageTestCase, self).setUp()\n",
    "        self.rb_storage = RBStorage()\n",
    "\n",
    "    def test_get_file_path(self):\n",
    "        func = RBStorage.get_file_path\n",
    "        self.assertEqual(func('img', 'file.jpg'), '/img/file.jpg')\n",
    "        self.assertEqual(func('img', 'file name.jpg'), '/img/file%20name.jpg')\n",
    "        self.assertEqual(func(u'h5/subdir/путь/to', 'file'), '/h5/subdir/%D0%BF%D1%83%D1%82%D1%8C/to/file')\n",
    "        self.assertRaises(RBStorageException, lambda: func('img', 'тест'))\n",
    "        self.assertRaises(RBStorageException, lambda: func('/img', 'file.jpg'))\n",
    "        self.assertRaises(RBStorageException, lambda: func('img/', 'file.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://pythontesting.net/meta/info-needed-to-start-testing/\n",
    "* https://www.youtube.com/watch?v=3MBT9O6i0jk&list=PLrCZzMib1e9pDKLsabJYuODdVJrHYc4Jd\n",
    "* https://en.wikipedia.org/wiki/Black-box_testing\n",
    "* https://en.wikipedia.org/wiki/Equivalence_partitioning\n",
    "* https://en.wikipedia.org/wiki/Boundary-value_analysis\n",
    "* https://stackoverflow.com/a/1952106\n",
    "* http://faker.readthedocs.io/en/master/#how-to-use-with-factory-boy\n",
    "* https://blog.acolyer.org/2017/11/30/the-role-of-software-in-spacecraft-accidents/\n",
    "* http://www.cse.psu.edu/~gxt29/bug/softwarebug.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* write tests\n",
    "* test everything everything important\n",
    "* document your tests\n",
    "* DRY does not apply to tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![pyramid](https://cdn-images-1.medium.com/max/1400/0*8Uapgla-XhuHS6ph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![units](https://dl.dropbox.com/s/aldfn9ewhy2pb3m/Units.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pylint: disable=C0301,W0105,W0401,W0614\n",
    "'''\n",
    "Tests for tarantool.response module\n",
    "'''\n",
    "import binascii\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "py3 = sys.version_info.major >= 3\n",
    "from_hex = lambda x: binascii.unhexlify(''.join(x.split()))\n",
    "to_hex = lambda x: binascii.hexlify(x)\n",
    "\n",
    "\n",
    "import tarantool.response\n",
    "\n",
    "\n",
    "class field(unittest.TestCase):\n",
    "    '''\n",
    "    Tests for response.field class\n",
    "    '''\n",
    "\n",
    "    def test__init_from_unicode(self):\n",
    "        '''\n",
    "        Test field instantiation from str or unicode value\n",
    "        '''\n",
    "        # Word \"Test\" in cyrillic utf-8 encoded\n",
    "        if py3:\n",
    "            value = str(b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\", \"utf-8\")\n",
    "        else:\n",
    "            value = unicode(b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\", \"utf-8\")\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(value),\n",
    "            b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\",\n",
    "            \"Instantiate field from unicode string\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def test__init_from_bytes(self):\n",
    "        '''\n",
    "        Test field instantiation from raw bytes value\n",
    "        '''\n",
    "        # Word \"Test\" in cyrillic utf-8 encoded\n",
    "        value = b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\"\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(value),\n",
    "            b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\",\n",
    "            \"Instantiate field from bytes\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def test__init_from_int(self):\n",
    "        '''\n",
    "        Test field instantiation from integer value\n",
    "        '''\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0),\n",
    "            b\"\\x00\\x00\\x00\\x00\",\n",
    "            \"Instantiate field from 32 bit integer value 0\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0x11223344),\n",
    "            b\"\\x44\\x33\\x22\\x11\",\n",
    "            \"Instantiate field from 32 bit integer value 0x11223344\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0x7fffffff),\n",
    "            b\"\\xff\\xff\\xff\\x7f\",\n",
    "            \"Instantiate field from 32 bit integer value 0x7fffffff\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0xffffffff),\n",
    "            b\"\\xff\\xff\\xff\\xff\",\n",
    "            \"Instantiate field from 32 bit integer value 0xffffffff\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0xffffffffffffffff),\n",
    "            b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\",\n",
    "            \"Instantiate field from 64 bit integer value 0xffffffffffffffff\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0x0100000000000000),\n",
    "            b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\",\n",
    "            \"Instantiate field from 64 bit integer value 0x0100000000000000\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.field(0x1122334455667788),\n",
    "            b\"\\x88\\x77\\x66\\x55\\x44\\x33\\x22\\x11\",\n",
    "            \"Instantiate field from 64 bit integer value 0x1122334455667788\"\n",
    "        )\n",
    "\n",
    "        # Out of range\n",
    "        with self.assertRaises(ValueError):\n",
    "            tarantool.response.field(0xffffffffffffffff+1)\n",
    "            tarantool.response.field(-1)\n",
    "\n",
    "        # Unsupported argument type\n",
    "        with self.assertRaises(TypeError):\n",
    "                tarantool.response.field(None)\n",
    "                tarantool.response.field([1,2,3])\n",
    "\n",
    "\n",
    "    def test__cast_to_int(self):\n",
    "        '''\n",
    "        Test type casting from field to int\n",
    "        '''\n",
    "        for i in (0, 0x11, 0x1122, 0x112233, 0xffffffff, 0xffffffffffffffff):\n",
    "            f = tarantool.response.field(i)\n",
    "            self.assertEqual(\n",
    "                int(f),\n",
    "                i,\n",
    "                \"Cast field instance to int, value = %d\"%i\n",
    "            )\n",
    "\n",
    "        # Can't cast string value to int\n",
    "        f = tarantool.response.field(b\"not an int value\")\n",
    "        with self.assertRaises(ValueError):\n",
    "            int(f)\n",
    "\n",
    "\n",
    "    def test__cast_to_str(self):\n",
    "        '''\n",
    "        Test type casting from field to str or unicode\n",
    "        '''\n",
    "        # Word \"Test\" in cyrillic utf-8 encoded\n",
    "        if py3:\n",
    "            self.assertEqual(\n",
    "                str(tarantool.response.field(b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\")),\n",
    "                str(b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\", \"utf-8\"),\n",
    "                \"Cast field instance to unicode\")\n",
    "        else:\n",
    "            self.assertEqual(\n",
    "                unicode(tarantool.response.field(b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\")),\n",
    "                unicode(b\"\\xd0\\xa2\\xd0\\xb5\\xd1\\x81\\xd1\\x82\", \"utf-8\"),\n",
    "                \"Cast field instance to unicode\")\n",
    "\n",
    "\n",
    "\n",
    "class Response(unittest.TestCase):\n",
    "    '''\n",
    "    Tests for response.Response\n",
    "    '''\n",
    "\n",
    "    def test__init_single(self):\n",
    "        '''\n",
    "        Test Response instance creation: unpack single record\n",
    "        '''\n",
    "        header = from_hex(\n",
    "            \"0d000000\" # request_type = 0x0d (\"insert\")\n",
    "            \"1b000000\" # body_length = 27\n",
    "            \"00000000\" # request_id\n",
    "        )\n",
    "\n",
    "        body = from_hex(\n",
    "            \"00000000\"    # return_code = 0\n",
    "            \"01000000\"    # count = 1\n",
    "            \"0b000000\"    # tuple_size = 11\n",
    "            \"02000000\"    # cardinality = 2\n",
    "                          # tuple = (1, \"JKLMN\")\n",
    "            \"04 01000000\" + \"05 4a4b4c4d4e\")\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.Response(header, body),\n",
    "            [(b\"\\x01\\x00\\x00\\x00\", b\"JKLMN\")],\n",
    "            \"Create Response instance: single record\"\n",
    "        )\n",
    "\n",
    "    def test__init_multiple(self):\n",
    "        '''\n",
    "        Test Response instance creation: unpack multiple records\n",
    "        '''\n",
    "        header = from_hex(\n",
    "            \"11000000\" # request_type = 0x11 (\"select\")\n",
    "            \"51000000\" # body_length = 32\n",
    "            \"00000000\" # request_id\n",
    "        )\n",
    "        body = from_hex(\n",
    "            \"00000000\" # return_code = 0\n",
    "            \"03000000\" # count = 3\n",
    "            \"10000000\" # tuple_size = 16 (0x10)\n",
    "            \"02000000\" # cardinality = 2\n",
    "                       # tuple = (1, \"1111111111\")\n",
    "            \"04 01000000\" + \"0a 31313131313131313131\"\n",
    "            \"10000000\" # tuple_size = 16 (0x10)\n",
    "            \"02000000\" # cardinality = 2\n",
    "                       # tuple = (2, \"2222222222\")\n",
    "            \"04 02000000\" + \"0a 32323232323232323232\"\n",
    "            \"11000000\" # tuple_size = 17 (0x11)\n",
    "            \"04000000\" # cardinality = 4\n",
    "                       # tuple = (3, \"LLL\", \"MMM\", \"NNN\")\n",
    "            \"04 03000000\" + \"03 4c4c4c\" + \"03 4d4d4d\" + \"03 4e4e4e\"\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            tarantool.response.Response(header, body),\n",
    "            [(b\"\\x01\\x00\\x00\\x00\", b\"1111111111\"),\n",
    "            (b\"\\x02\\x00\\x00\\x00\", b\"2222222222\"),\n",
    "            (b\"\\x03\\x00\\x00\\x00\", b\"LLL\", b\"MMM\", b\"NNN\")],\n",
    "            \"Create Response instance - multiple records with multiple fields\"\n",
    "        )\n",
    "\n",
    "    def test__init_attrs(self):\n",
    "\n",
    "        # Check instanse attributes\n",
    "\n",
    "        header = from_hex(\"0d00000014000000 11223344\")\n",
    "        body = from_hex(\"00000000010000000400000002000000014b015a\")\n",
    "        r = tarantool.response.Response(header, body)\n",
    "\n",
    "        self.assertEqual(r.return_code, 0, \"Check return_code property\")\n",
    "        self.assertIsNone(r.return_message, \"Check return_message property\")\n",
    "        self.assertEqual(r.return_code, 0, \"Check completion_status property\")\n",
    "        self.assertEqual(r.rowcount, 1, \"Check rowcount property\")\n",
    "        self.assertEqual(r._body_length, 20, \"Check _body_length attribute\")\n",
    "        self.assertEqual(r._request_id, 0x44332211, \"Check _request_id attribute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pylint: disable=C0301,W0105,W0401,W0614\n",
    "'''\n",
    "Tests for tarantool.request module\n",
    "'''\n",
    "\n",
    "import binascii\n",
    "import unittest\n",
    "\n",
    "\n",
    "import tarantool.request\n",
    "\n",
    "\n",
    "class RequestInsert(unittest.TestCase):\n",
    "\n",
    "    def test__cast_to_bytes(self):\n",
    "        '''\n",
    "        Test binary INSERT request representation\n",
    "        '''\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestInsert(1, (1, 2000, 30000), False)),\n",
    "            binascii.unhexlify(\"0d0000001b00000000000000010000000000000003000000040100000004d00700000430750000\")\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestInsert(1, (b\"AAA\", b\"BBBB\", b\"CCCCCC\"), False)),\n",
    "            binascii.unhexlify(\"0d0000001c0000000000000001000000000000000300000003414141044242424206434343434343\")\n",
    "        )\n",
    "\n",
    "\n",
    "class RequestDelete(unittest.TestCase):\n",
    "\n",
    "    def test__cast_to_bytes(self):\n",
    "        '''\n",
    "        Test binary DELETE request representation\n",
    "        '''\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestDelete(1, 1, False)),\n",
    "            binascii.unhexlify(\"1500000011000000000000000100000000000000010000000401000000\")\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestDelete(1, b\"AAA\", False)),\n",
    "            binascii.unhexlify(\"15000000100000000000000001000000000000000100000003414141\")\n",
    "        )\n",
    "\n",
    "        # Raises a TypeError exception because the primary key must be a scalar value (int or str)\n",
    "        with self.assertRaises(TypeError):\n",
    "            tarantool.request.RequestDelete(1, [1,2], False)\n",
    "\n",
    "\n",
    "class RequestSelect(unittest.TestCase):\n",
    "\n",
    "    def test__cast_to_bytes(self):\n",
    "        '''\n",
    "        Test binary SELECT request representation\n",
    "        '''\n",
    "        # select * from t1 where k0 = 1\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestSelect(1, 0, [(1,)], 0, 0xffff)),\n",
    "            binascii.unhexlify(\"110000001d00000000000000010000000000000000000000ffff000001000000010000000401000000\"),\n",
    "            \"Select using integer key\"\n",
    "        )\n",
    "\n",
    "        # select * from t1 where k0 = \"AAA\"\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestSelect(1, 0, [(b\"AAA\",)], 0, 0xffff)),\n",
    "            binascii.unhexlify(\"110000001c00000000000000010000000000000000000000ffff0000010000000100000003414141\"),\n",
    "            \"Select using string key\"\n",
    "        )\n",
    "\n",
    "        # select * from t1 where k0 in (1, 2, 3)\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestSelect(1, 0, [(1,), (2,), (3,)], 0, 0xffff)),\n",
    "            binascii.unhexlify(\"110000002f00000000000000010000000000000000000000ffff000003000000010000000401000000010000000402000000010000000403000000\"),\n",
    "            \"Select multiple keys\"\n",
    "        )\n",
    "\n",
    "        # select * from t1 where k0 = (1, 2)\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestSelect(1, 0, [(1, 2)], 0, 0xffff)),\n",
    "            binascii.unhexlify(\"110000002200000000000000010000000000000000000000ffff0000010000000200000004010000000402000000\"),\n",
    "            \"Select using composite index\"\n",
    "        )\n",
    "\n",
    "        # select * from t1 where k0 = (1, 2) or k0 = (3, 4)\n",
    "        self.assertEqual(\n",
    "            bytes(tarantool.request.RequestSelect(1, 0, [(1, 2), (3, 4)], 0, 0xffff)),\n",
    "            binascii.unhexlify(\"110000003000000000000000010000000000000000000000ffff00000200000002000000040100000004020000000200000004030000000404000000\"),\n",
    "            \"Select multiple keys using composite index\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Coverage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def add(a, b):\n",
    "    if isinstance(a, int) and isinstance(b, int):\n",
    "        return a + b\n",
    "    elif isinstance(a, str) and isinstance(b, str):\n",
    "        return int(a) + intg(b)\n",
    "    else:\n",
    "        raise Exception('Invalid arguments')\n",
    " \n",
    " \n",
    "class Test(unittest.TestCase): \n",
    "    def test_add(self):\n",
    "        self.assertEqual(5, add(2, 3))\n",
    "        self.assertEqual(15, add(-6, 21))\n",
    "        self.assertRaises(Exception, add, 4.0, 5.0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def to_perc(x, total):\n",
    "    if x > total:\n",
    "        raise ValueError(\"Nonsense!\")\n",
    "    return x * 100.0 / total\n",
    " \n",
    "\n",
    "class Test(unittest.TestCase): \n",
    "    def test_add(self):\n",
    "        self.assertEqual(0, to_perc(0, 100))\n",
    "        self.assertEqual(100, to_perc(100, 100))\n",
    "        self.assertEqual(100, to_perc(100, 100))\n",
    "        self.assertRaises(Exception, to_perc, 101, 100)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding: utf8\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import shlex\n",
    "import shutil\n",
    "import hashlib\n",
    "import resource\n",
    "import unittest\n",
    "import subprocess\n",
    "\n",
    "\n",
    "import fstore\n",
    "\n",
    "DATA_DIR = \"/tmp/fstore_test/\"\n",
    "NUM_KEYS = 100\n",
    "rss = lambda: resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "\n",
    "def sh(command, out=False, env=None):\n",
    "    if out:\n",
    "        p = subprocess.Popen(shlex.split(command), shell=False, env=env, stdout=subprocess.PIPE, stderr=sys.stderr)\n",
    "        return p.communicate()[0]\n",
    "    else:\n",
    "        p = subprocess.Popen(shlex.split(command), shell=False, env=env, stderr=sys.stderr)\n",
    "        return p.wait()\n",
    "\n",
    "\n",
    "def get_md5_hash(s):\n",
    "    m = hashlib.md5()\n",
    "    m.update(s)\n",
    "    return m.hexdigest()\n",
    "\n",
    "\n",
    "def regular_keysplit(key):\n",
    "    return key[0] + \"/\" + key[1:3] + \"/\" + key[3:5], key[5:]\n",
    "\n",
    "\n",
    "def get_open_fds():\n",
    "    pid = os.getpid()\n",
    "    procs = sh(\"lsof -w -Ff -p %s\" % str(pid), out=True)\n",
    "    nprocs = len(\n",
    "        filter(\n",
    "            lambda s: s and s[0] == 'f' and s[1:].isdigit(),\n",
    "            procs.split('\\n'))\n",
    "    )\n",
    "    return nprocs\n",
    "\n",
    "\n",
    "def gc_leak_check(func, *args, **kwargs):\n",
    "    last, l = 0, 0\n",
    "    gc.collect()\n",
    "    last_rss = rss()\n",
    "    last = len(gc.get_objects())\n",
    "    for x in xrange(100):\n",
    "        func(*args, **kwargs)\n",
    "        gc.collect()\n",
    "        l = len(gc.get_objects())\n",
    "        lr = rss()\n",
    "        if x > 0:\n",
    "            assert last_rss == lr, \"RSS changed: %s != %s\" % (last_rss, lr)\n",
    "            assert last == l, \"GC objects count changed: %s != %s\" % (last, l)\n",
    "        last = l\n",
    "        last_rss = lr\n",
    "\n",
    "\n",
    "def write_features_file(path, content):\n",
    "    with open(path, \"w\") as fp:\n",
    "        for d in content:\n",
    "            parts = [d[\"key\"].encode(\"utf8\")]\n",
    "            for k in sorted(d.keys()):\n",
    "                if k != \"key\":\n",
    "                    f = u\" \".join([u\"%s %s\" % (f, c) for f, c in d[k]])\n",
    "                    parts.append(f.encode(\"utf8\"))\n",
    "            fp.write(\"\\t\".join(parts))\n",
    "            fp.write(\"\\n\")\n",
    "\n",
    "\n",
    "class TestFStoreGetFrom(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        path, content = make_features_file(\"ff0\")\n",
    "        self.features_file_path = path\n",
    "        self.content = content\n",
    "\n",
    "    def tearDown(self):\n",
    "        if os.path.exists(DATA_DIR):\n",
    "            shutil.rmtree(DATA_DIR)\n",
    "\n",
    "    def test_get_first(self):\n",
    "        user_features = self.content[0]\n",
    "        got_features1, got_features2 = fstore.get_from(self.features_file_path, user_features[\"key\"])\n",
    "        self.assertEqual(user_features[\"features1\"], got_features1)\n",
    "        self.assertEqual(user_features[\"features2\"], got_features2)\n",
    "\n",
    "    def test_get_last(self):\n",
    "        user_features = self.content[-1]\n",
    "        got_features1, got_features2 = fstore.get_from(self.features_file_path, user_features[\"key\"])\n",
    "        self.assertEqual(user_features[\"features1\"], got_features1)\n",
    "        self.assertEqual(user_features[\"features2\"], got_features2)\n",
    "\n",
    "    def test_get_mid(self):\n",
    "        user_features = self.content[len(self.content) / 2]\n",
    "        got_features1, got_features2 = fstore.get_from(self.features_file_path, user_features[\"key\"])\n",
    "        self.assertEqual(user_features[\"features1\"], got_features1)\n",
    "        self.assertEqual(user_features[\"features2\"], got_features2)\n",
    "\n",
    "    def test_user_not_exists(self):\n",
    "        res = fstore.get_from(self.features_file_path, \"nosuchkey\")\n",
    "        self.assertEqual(res, None)\n",
    "\n",
    "    def test_get_from_compressed_file(self):\n",
    "        path, content = make_features_file(\"ff0\", lz4=True)\n",
    "        user_features = content[len(content) / 2]\n",
    "        no_ext_path = path[:-4]\n",
    "        if os.path.exists(no_ext_path):\n",
    "            os.remove(no_ext_path)\n",
    "        self.assertTrue(len(os.listdir(DATA_DIR)) == 1 and os.listdir(DATA_DIR)[0].endswith(\".lz4\"))\n",
    "        got_features1, got_features2 = fstore.get_from(no_ext_path, user_features[\"key\"])\n",
    "        self.assertEqual(user_features[\"features1\"], got_features1)\n",
    "        self.assertEqual(user_features[\"features2\"], got_features2)\n",
    "\n",
    "    def test_get_from_file_w_grp_counts(self):\n",
    "        path, content = make_features_file(\"ff0\", include_grp_counts=True)\n",
    "        for user_features in content:\n",
    "            got_features = fstore.get_from(self.features_file_path, user_features[\"key\"])\n",
    "            self.assertEqual(user_features[\"features1\"], got_features[0])\n",
    "            self.assertEqual(user_features[\"features2\"], got_features[1])\n",
    "            self.assertEqual(user_features[\"features3\"], got_features[2])\n",
    "\n",
    "    def test_mem_leak(self):\n",
    "        user_features = self.content[-1]\n",
    "        gc_leak_check(fstore.get_from, self.features_file_path, \"nosuchkey\")\n",
    "        gc_leak_check(fstore.get_from, self.features_file_path, user_features[\"key\"])\n",
    "\n",
    "    def test_fd_leak(self):\n",
    "        user_features = self.content[-1]\n",
    "        nf = get_open_fds()\n",
    "        fstore.get_from(self.features_file_path, user_features[\"key\"])\n",
    "        nl = get_open_fds()\n",
    "        self.assertEqual(nf, nl)\n",
    "\n",
    "    def test_throw_errors(self):\n",
    "        self.assertRaises(fstore.FStoreException, fstore.get_from, \"nosuchfile\", \"nosuchkey\")\n",
    "\n",
    "    def test_special_cases(self):\n",
    "        path, content = make_cornercase_file()\n",
    "        for u in content:\n",
    "            got_features1, got_features2 = fstore.get_from(path, u[\"key\"])\n",
    "            if not u[\"features1\"] and u[\"features2\"]:\n",
    "                self.assertEqual((u[\"features2\"], u[\"features1\"]), (got_features1, got_features2))\n",
    "            else:\n",
    "                self.assertEqual((u[\"features1\"], u[\"features2\"]), (got_features1, got_features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import sys\n",
    "import Queue\n",
    "import hashlib\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '../../../test/base'))\n",
    "import box\n",
    "import mem\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "from vk_profiles_refresher import VKProfileUpdater, _sentinel, VKProfile, VKAPI\n",
    "\n",
    "# more imports. Skipped.\n",
    "\n",
    "\n",
    "VKPROFILES_SCHEMA = VKProfile.schema\n",
    "TARANTOOL_VKPROFILES_CONFIG = \"\"\"\n",
    "space[0].enabled = 1\n",
    "space[0].index[0].type = \"HASH\"\n",
    "space[0].index[0].unique = 1\n",
    "space[0].index[0].key_field[0].fieldno = 0\n",
    "space[0].index[0].key_field[0].type = \"NUM\"\n",
    "\n",
    "...\n",
    "more config. Skipped.\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class VKAPIMock(VKAPI):\n",
    "    def __init__(self, token, salt):\n",
    "        super(VKAPIMock, self).__init__(token, salt)\n",
    "        self.response = {\"error\": {\"error_code\": 9, \"error_msg\": \"Flood control\"}}\n",
    "\n",
    "    def query(self, url):\n",
    "        self.url = url\n",
    "        return {\"response\": [self.response] if not isinstance(self.response, list) else self.response}\n",
    "\n",
    "\n",
    "class RefresherTestCase(TestBaseRb):\n",
    "    def setUp(self):\n",
    "        self.config = {\n",
    "            \"FORCE\": True,\n",
    "            \"TARANTELLA_UID\": \"127.0.0.1:%s\" % mem.MEMCACHED_PORT,\n",
    "            \"VK_PROFILES_SPACE\": 0,\n",
    "            \"TARANTOOL_VK_PROFILES\": {\n",
    "                \"host\": \"127.0.0.1\",\n",
    "                \"port\": box.TARANTOOL_PRIMARY_PORT,\n",
    "            },\n",
    "            \"VK\": {\n",
    "                \"salt\": \"42\",\n",
    "                \"token\": \"42\",\n",
    "            },\n",
    "        }\n",
    "        box.config(TARANTOOL_VKPROFILES_CONFIG)\n",
    "        box.start()\n",
    "        mem.start()\n",
    "        self.tarantools = {\"vk_profiles\": box, \"uid\": mem}\n",
    "        self.queue = Queue.Queue()\n",
    "        self.updater = VKProfileUpdater(self.queue, self.config)\n",
    "        self.updater.vk_api = VKAPIMock(self.config[\"VK\"][\"token\"], self.config[\"VK\"][\"salt\"])\n",
    "\n",
    "    def tearDown(self):\n",
    "        mem.stop()\n",
    "        box.stop()\n",
    "\n",
    "    # more methods. Skipped.\n",
    "\n",
    "    def set_vk_api_response_profile(self, response):\n",
    "        self.updater.vk_api.response = response\n",
    "\n",
    "    def update_profiles(self):\n",
    "        self.queue.put(_sentinel)\n",
    "        self.updater.run()\n",
    "\n",
    "    def check_vk_api_request(self, expected_requested_vk_ids):\n",
    "        api_requests = [{\"uri\": self.updater.vk_api.url, \"headers\": self.updater.vk_api.session.headers}]\n",
    "        if expected_requested_vk_ids is None:\n",
    "            self.assertEqual([], api_requests)\n",
    "        else:\n",
    "            expected_requested_vk_ids = \",\".join(map(str, expected_requested_vk_ids))\n",
    "            self.assertEqual(1, len(api_requests))\n",
    "            self.assertEqual('Rb.Mail.Ru/2.0', api_requests[0]['headers']['User-Agent'])\n",
    "            uri_path, url_params = api_requests[0]['uri'].split('?', 1)\n",
    "            self.assertEqual('https://api.vk.com/method/adsint.usersGet', uri_path)\n",
    "            url_params = url_params.split('&')\n",
    "            msig = hashlib.md5('adsint.usersGet' + str(expected_requested_vk_ids) +\n",
    "                               self.config[\"VK\"][\"salt\"]).hexdigest()\n",
    "            expected_url_params = ['user_ids=%s' % expected_requested_vk_ids,\n",
    "                                   'access_token=' + self.config[\"VK\"][\"token\"],\n",
    "                                   'msig=%s' % msig]\n",
    "            self.assertItemsEqual(expected_url_params, url_params)\n",
    "\n",
    "    def check(self, expected_profiles=None, expected_requested_vk_ids=None):\n",
    "        profiles = self.get_profiles_from_tarantool(self.tarantools['vk_profiles'])\n",
    "        if expected_profiles is None:\n",
    "            self.assertEqual([], profiles)\n",
    "        else:\n",
    "            self.assertEqual(len(profiles), len(expected_profiles))\n",
    "            for profile, expected_profile in zip(profiles, expected_profiles):\n",
    "                if profile and profile['mtime'] - expected_profile['mtime'] <= 2:\n",
    "                    expected_profile['mtime'] = profile['mtime']\n",
    "                self.assertEqual(qalib.merge_filter_dict(vk.default_profile, expected_profile), profile)\n",
    "        self.check_vk_api_request(expected_requested_vk_ids)\n",
    "\n",
    "    def test_nothing(self):\n",
    "        self.queue.put(_sentinel)\n",
    "        self.updater.run()\n",
    "\n",
    "    def test_milti_update(self):\n",
    "        self.set_vk_api_response_profile([\n",
    "            {'uid': 123, 'bdate': '26.10.1978', 'sex': 2},\n",
    "            {'uid': 127, 'bdate': '26.10.1978', 'sex': 1},\n",
    "            {'uid': 125, 'bdate': '26.10.1978', 'sex': 1},\n",
    "            {'uid': 122, 'bdate': '26.10.1978', 'sex': 1},\n",
    "            {'error': {'error_code': 9, 'error_msg': 'Flood control'}},\n",
    "            {'uid': 128, 'deactivated': 'banned'},\n",
    "            {'uid': 226, 'bdate': '26.10.1978', 'sex': 1},\n",
    "            {'uid': 126, 'bdate': '26.10.1978', 'sex': 1},\n",
    "            {'uid': 124, 'bdate': '26.10.1978', 'sex': 1},\n",
    "        ])\n",
    "        bd = 1978 * 65536 + 10 * 256 + 26\n",
    "        updating_profiles = [\n",
    "            {'vk_id': 123, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 124, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 125, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 126, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 127, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 128, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 129, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "            {'vk_id': 130, 'gender': 2, 'birthday': bd, 'mtime': 0},\n",
    "        ]\n",
    "        expected_profiles = [\n",
    "            {'vk_id': 123, 'gender': 1, 'birthday': bd, 'mtime': rbcookies.now()},\n",
    "            {'vk_id': 124, 'gender': 2, 'birthday': bd, 'mtime': rbcookies.now()},\n",
    "            {'vk_id': 125, 'gender': 2, 'birthday': bd, 'mtime': rbcookies.now()},\n",
    "            {'vk_id': 126, 'gender': 2, 'birthday': bd, 'mtime': rbcookies.now()},\n",
    "            {'vk_id': 127, 'gender': 2, 'birthday': bd, 'mtime': rbcookies.now()},\n",
    "        ]\n",
    "        self.set_tarantool_vk_profile(self.tarantools['vk_profiles'], profiles=updating_profiles)\n",
    "        self.update_profiles()\n",
    "        requested_vk_ids = [p[\"vk_id\"] for p in updating_profiles]\n",
    "        self.check(expected_profiles=expected_profiles, expected_requested_vk_ids=requested_vk_ids)\n",
    "\n",
    "    def test_requests_api_unicode(self):\n",
    "        import sys\n",
    "        reload(sys)\n",
    "        sys.setdefaultencoding('ascii')\n",
    "        profile = {'vk_id': 123, 'gender': 1, 'birthday': 1990 * 65536 + 1 * 256 + 13,\n",
    "                   'mtime': 0}\n",
    "        self.set_tarantool_vk_profile(self.tarantools['vk_profiles'], profiles=[profile])\n",
    "        self.set_vk_api_response_profile({'uid': 123, 'bdate': u'26.10.1978', 'sex': 1,\n",
    "                                          'first_name': u'Имя', 'last_name': u'Фамилия'})\n",
    "        expected_profile = {'vk_id': 123, 'gender': 2, 'birthday': 1978 * 65536 + 10 * 256 + 26,\n",
    "                            'mtime': rbcookies.now(), 'first_name': u'Имя'.encode(\"utf-8\"),\n",
    "                            'last_name': u'Фамилия'.encode(\"utf-8\")}\n",
    "        self.update_profiles()\n",
    "        self.check(expected_profiles=[expected_profile], expected_requested_vk_ids=[123])\n",
    "\n",
    "    @factory([0, 1, 100])\n",
    "    def test_requests_api_when_profile_very_old(self, mtime):\n",
    "        profile = {'vk_id': 123, 'gender': 1, 'birthday': 1990 * 65536 + 1 * 256 + 13,\n",
    "                   'mtime': mtime}\n",
    "        self.set_tarantool_vk_profile(self.tarantools['vk_profiles'], profiles=[profile])\n",
    "        self.set_vk_api_response_profile({'uid': 123, 'bdate': '26.10.1978', 'sex': 1})\n",
    "        expected_profile = {'vk_id': 123, 'gender': 2, 'birthday': 1978 * 65536 + 10 * 256 + 26,\n",
    "                            'mtime': rbcookies.now()}\n",
    "        self.update_profiles()\n",
    "        self.check(expected_profiles=[expected_profile], expected_requested_vk_ids=[123])\n",
    "\n",
    "    @factory(['xxx', '2.3', '1.-2.3', '1.2.-3', '1'])\n",
    "    def test_ignores_invalid_birthday_from_api_response(self, api_birthday):\n",
    "        self.set_vk_api_response_profile({'uid': 123, 'bdate': api_birthday, 'sex': 1})\n",
    "        expected_profile = {'vk_id': 123, 'gender': 2,\n",
    "                            'birthday': 0,\n",
    "                            'mtime': rbcookies.now()}\n",
    "        self.set_tarantool_vk_profile(self.tarantools['vk_profiles'], profiles=[{\"vk_id\": 123}])\n",
    "        self.update_profiles()\n",
    "        self.check(expected_profiles=[expected_profile], expected_requested_vk_ids=[123])\n",
    "\n",
    "    def test_ignores_unknown_field_in_api_response(self):\n",
    "        self.set_vk_api_response_profile({'uid': 123, 'bdate': '26.10.1978', 'sex': 1, 'xxx': 123, 'yyy': 'qwe'})\n",
    "        expected_profile = {'vk_id': 123, 'gender': 2, 'birthday': 1978 * 65536 + 10 * 256 + 26,\n",
    "                            'mtime': rbcookies.now()}\n",
    "        self.set_tarantool_vk_profile(self.tarantools['vk_profiles'], profiles=[{\"vk_id\": 123}])\n",
    "        self.update_profiles()\n",
    "        self.check(expected_profiles=[expected_profile], expected_requested_vk_ids=[123])\n",
    "\n",
    "    # more methods. Skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Selenium__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MainPage(Page):\n",
    "    page_url = \"https://mail.ru/\"\n",
    "\n",
    "    def auth(self):\n",
    "        try:\n",
    "            login_field = self.webdriver.find_element_by_id('mailbox__login')\n",
    "            password_field = self.webdriver.find_element_by_id('mailbox__password')\n",
    "            auth_button = self.webdriver.find_element_by_id('mailbox__auth__button')\n",
    "        except NoSuchElementException:\n",
    "            return\n",
    "        login_field.send_keys(conf.mail.login)\n",
    "        password_field.send_keys(conf.mail.password)\n",
    "        try:\n",
    "            auth_button.click()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from django.contrib.staticfiles.testing import StaticLiveServerTestCase\n",
    "from selenium.webdriver.firefox.webdriver import WebDriver\n",
    "\n",
    "class MySeleniumTests(StaticLiveServerTestCase):\n",
    "    fixtures = ['user-data.json']\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        super(MySeleniumTests, cls).setUpClass()\n",
    "        cls.selenium = WebDriver()\n",
    "        cls.selenium.implicitly_wait(10)\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.selenium.quit()\n",
    "        super(MySeleniumTests, cls).tearDownClass()\n",
    "\n",
    "    def test_login(self):\n",
    "        self.selenium.get('%s%s' % (self.live_server_url, '/login/'))\n",
    "        username_input = self.selenium.find_element_by_name(\"username\")\n",
    "        username_input.send_keys('myuser')\n",
    "        password_input = self.selenium.find_element_by_name(\"password\")\n",
    "        password_input.send_keys('secret')\n",
    "        self.selenium.find_element_by_xpath('//input[@value=\"Log in\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a *verification* activity; did we build a correctly working product? Does the software meet the business requirements?\n",
    "\n",
    "For this type of testing we have test cases that cover all the possible scenarios we can think of, even if that scenario is unlikely to exist \"in the real world\". When doing this type of testing, we aim for maximum code coverage. We use any test environment we can grab at the time, it doesn't have to be \"production\" caliber, so long as it's usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceptance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a *validation* activity. Did we build the right thing? Is this what the customer really needs?\n",
    "\n",
    "This is usually done in cooperation with the customer, or by an internal customer proxy (product owner). For this type of testing we use test cases that cover the typical scenarios under which we expect the software to be used. This test must be conducted in a \"production-like\" environment, on hardware that is the same as, or close to, what a customer will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anti-patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cone](https://insights-images.thoughtworks.com/Architecting20for20Continuous20Delivery01_202d425a8633fb31e8046fccf37f8a26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Broken atomicity__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_add_smth():\n",
    "    user = create_new_user(email=‘some@ema.il’)\n",
    "    user.register()\n",
    "    user.auth()\n",
    "    smth = user.create_smth()\n",
    "    smth.add()\n",
    "    check(user.is_authorized())\n",
    "    check(smth.is_added())\n",
    "    check(‘some@ema.il’ == user.email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Liar__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_some_feature(self):\n",
    "    do_smth()\n",
    "    self.assertTrue(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Giant__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![god](https://habrastorage.org/storage2/4b3/14a/414/4b314a414b39ff15f116d6f99841b65c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Secret Catcher__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_smth_one_two_three(self):\n",
    "    do_smth1()\n",
    "    do_smth2()\n",
    "    do_smth3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Inspector__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_obj(self):\n",
    "    # …\n",
    "    self.assertTrue(42, test_obj._answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Slowpoke__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_pokemon(self):\n",
    "    do_smth1()\n",
    "    time.sleep(N)\n",
    "    self.assertSmth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://pythontesting.net/strategy/why-most-unit-testing-is-waste/\n",
    "* https://blog.kentcdodds.com/write-tests-not-too-many-mostly-integration-5e8c7fff591c?gi=822c526c6ab2\n",
    "* https://books.google.ru/books/about/How_Google_Tests_Software.html?id=vHlTOVTKHeUC&redir_esc=y\n",
    "* http://chimera.labs.oreilly.com/books/1234000000754\n",
    "* https://www.amazon.com/Test-Driven-Development-Kent-Beck/dp/0321146530\n",
    "* https://blogs.msdn.microsoft.com/ericgu/2017/06/22/notdd/\n",
    "* http://neverworkintheory.org/2016/10/05/test-driven-development.html\n",
    "* https://www.youtube.com/watch?v=FEs2jgZBaQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* write tests\n",
    "* not too many\n",
    "* integration mostly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you mock something you’re basically removing all confidence in the integration between what you’re testing and what’s being mocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MockResponse(object):\n",
    "    def __init__(self, status_code=200, data='OK', headers=None):\n",
    "        self.status = status_code\n",
    "        self.data = data\n",
    "        self.headers = headers\n",
    "\n",
    "    def read(self):\n",
    "        return self.data\n",
    "\n",
    "    def getheader(self, header_name, default):\n",
    "        return (self.headers or {}).get(header_name, default)\n",
    "\n",
    "    def getheaders(self):\n",
    "        return self.headers or {}\n",
    "\n",
    "    \n",
    "class MockRBStorageConnection(object):\n",
    "    def __init__(self, connect_string, timeout):\n",
    "        self.connect_string = connect_string\n",
    "        self.timeout = timeout\n",
    "        self.response = None\n",
    "        self.content_cache = {}\n",
    "\n",
    "    def request(self, method, file_path, content=None):\n",
    "        global _attemps\n",
    "\n",
    "        if method == 'GET':\n",
    "            self.response = MockResponse(data=self.content_cache[file_path].read())\n",
    "            return\n",
    "\n",
    "        if method == 'HEAD':\n",
    "            content = self.content_cache[file_path].read()\n",
    "            self.response = MockResponse(headers=(('content-length', str(len(content))),))\n",
    "            return\n",
    "\n",
    "        extention = os.path.splitext(file_path)[1]\n",
    "        bucket = file_path.split('/')[1]\n",
    "\n",
    "        if bucket != 'img':\n",
    "            self.response = MockResponse(status_code=404)\n",
    "            return\n",
    "\n",
    "        if 'bad' in file_path:\n",
    "            self.response = MockResponse(headers={})\n",
    "            return\n",
    "\n",
    "        if 'tmp_error' in file_path:\n",
    "            if not _attemps:\n",
    "                _attemps += 1\n",
    "                raise Exception('timeout')\n",
    "\n",
    "        if 'permanent_error' in file_path:\n",
    "            raise Exception('timeout')\n",
    "\n",
    "        _attemps = 0\n",
    "        file_dir, file_name = get_hash_tuple_from_content(content)\n",
    "\n",
    "        headers = {'x-filename': '/{bucket}/{file_dir}/{file_name}{extention}'.format(\n",
    "            file_dir=file_dir, file_name=file_name, extention=extention, bucket=bucket\n",
    "        )}\n",
    "\n",
    "        self.content_cache[headers['x-filename']] = content\n",
    "        self.response = MockResponse(headers=headers)\n",
    "\n",
    "    def getresponse(self):\n",
    "        return self.response\n",
    "\n",
    "    def set_debuglevel(self, level):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square(value):\n",
    "    return value ** 2\n",
    "\n",
    "def cube(value): \n",
    "    return value ** 3\n",
    "\n",
    "def main(value): \n",
    "    return square(value) + cube(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import mock\n",
    "except ImportError:\n",
    "    from unittest import mock\n",
    "\n",
    "import unittest\n",
    "\n",
    "from function import square, main\n",
    "\n",
    "\n",
    "class TestNotMockedFunction(unittest.TestCase):\n",
    "\n",
    "    @mock.patch('__main__.square', return_value=1)\n",
    "    def test_function(self, mocked_square):\n",
    "        # because you need to patch in exact place where function that has to be mocked is called\n",
    "        self.assertEquals(square(5), 1)\n",
    "\n",
    "    @mock.patch('function.square')\n",
    "    @mock.patch('function.cube')\n",
    "    def test_main_function(self, mocked_square, mocked_cube):\n",
    "        # underling function are mocks so calling main(5) will return mock\n",
    "        mocked_square.return_value = 1\n",
    "        mocked_cube.return_value = 0\n",
    "        self.assertEquals(main(5), 1)\n",
    "        mocked_square.assert_called_once_with(5)\n",
    "        mocked_cube.assert_called_once_with(5)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from function import square, main\n",
    "\n",
    "def test_function(monkeypatch):\n",
    "    monkeypatch.setattr(“test_function_pytest.square”, lambda x: 1)\n",
    "    assert square(5) == 1\n",
    "\n",
    "def test_main_function(monkeypatch): \n",
    "    monkeypatch.setattr(‘function.square’, lambda x: 1) \n",
    "    monkeypatch.setattr(‘function.cube’, lambda x: 0) \n",
    "    assert main(5) == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monkey patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mock import patch\n",
    "\n",
    "def freeze_zip(func):\n",
    "    \"\"\"\n",
    "        Использовать как декоратор для тестов, чтобы хэш от zip-архива не менялся со временем\n",
    "        и не зависел от платформы\n",
    "\n",
    "    \"\"\"\n",
    "    patch1 = patch('zipfile.time.localtime', new=lambda x: (2015, 1, 1, 0, 0, 0))\n",
    "    patch2 = patch('zipfile.sys.platform', new='linux2')\n",
    "    return patch1(patch2(func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MonkeypatchPlugin:\n",
    "    \"\"\" setattr-monkeypatching with automatical reversal after test. \"\"\"\n",
    "    def pytest_pyfuncarg_monkeypatch(self, pyfuncitem):\n",
    "        monkeypatch = MonkeyPatch()\n",
    "        pyfuncitem.addfinalizer(monkeypatch.finalize)\n",
    "        return monkeypatch\n",
    " \n",
    "notset = object()\n",
    " \n",
    "class MonkeyPatch:\n",
    "    def __init__(self):\n",
    "        self._setattr = []\n",
    "        self._setitem = []\n",
    " \n",
    "    def setattr(self, obj, name, value):\n",
    "        self._setattr.insert(0, (obj, name, getattr(obj, name, notset)))\n",
    "        setattr(obj, name, value)\n",
    " \n",
    "    def setitem(self, dictionary, name, value):\n",
    "        self._setitem.insert(0, (dictionary, name, dictionary.get(name, notset)))\n",
    "        dictionary[name] = value\n",
    " \n",
    "    def finalize(self):\n",
    "        for obj, name, value in self._setattr:\n",
    "            if value is not notset:\n",
    "                setattr(obj, name, value)\n",
    "            else:\n",
    "                delattr(obj, name)\n",
    "        for dictionary, name, value in self._setitem:\n",
    "            if value is notset:\n",
    "                del dictionary[name]\n",
    "            else:\n",
    "                dictionary[name] = value\n",
    " \n",
    " \n",
    "def test_setattr():\n",
    "    class A:\n",
    "        x = 1\n",
    "    monkeypatch = MonkeyPatch()\n",
    "    monkeypatch.setattr(A, 'x', 2)\n",
    "    assert A.x == 2\n",
    "    monkeypatch.setattr(A, 'x', 3)\n",
    "    assert A.x == 3\n",
    "    monkeypatch.finalize()\n",
    "    assert A.x == 1\n",
    " \n",
    "    monkeypatch.setattr(A, 'y', 3)\n",
    "    assert A.y == 3\n",
    "    monkeypatch.finalize()\n",
    "    assert not hasattr(A, 'y')\n",
    " \n",
    " \n",
    "def test_setitem():\n",
    "    d = {'x': 1}\n",
    "    monkeypatch = MonkeyPatch()\n",
    "    monkeypatch.setitem(d, 'x', 2)\n",
    "    monkeypatch.setitem(d, 'y', 1700)\n",
    "    assert d['x'] == 2\n",
    "    assert d['y'] == 1700\n",
    "    monkeypatch.setitem(d, 'x', 3)\n",
    "    assert d['x'] == 3\n",
    "    monkeypatch.finalize()\n",
    "    assert d['x'] == 1\n",
    "    assert 'y' not in d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def setup():\n",
    "    print (\"basic setup into module\")\n",
    "\n",
    "def teardown():\n",
    "    print (\"basic teardown into module\")\n",
    "\n",
    "def setup_module(module):\n",
    "    print (\"module setup\")\n",
    "\n",
    "def teardown_module(module):\n",
    "    print (\"module teardown\")\n",
    "\n",
    "def setup_function(function):\n",
    "    print (\"function setup\")\n",
    "\n",
    "def teardown_function(function):\n",
    "    print (\"function teardown\")\n",
    "\n",
    "def test_numbers_3_4():\n",
    "    print \"test 3*4\"\n",
    "    assert 3*4 == 12 \n",
    "\n",
    "def test_strings_a_3():\n",
    "    print \"test a*3\"\n",
    "    assert 'a'*3 == 'aaa' \n",
    "\n",
    "\n",
    "class TestUM:\n",
    "    def setup(self):\n",
    "        print (\"basic setup into class\")\n",
    " \n",
    "    def teardown(self):\n",
    "        print (\"basic teardown into class\")\n",
    " \n",
    "    def setup_class(cls):\n",
    "        print (\"class setup\")\n",
    " \n",
    "    def teardown_class(cls):\n",
    "        print (\"class teardown\")\n",
    " \n",
    "    def setup_method(self, method):\n",
    "        print (\"method setup\")\n",
    " \n",
    "    def teardown_method(self, method):\n",
    "        print (\"method teardown\")\n",
    " \n",
    "    def test_numbers_5_6(self):\n",
    "        print \"test 5*6\"\n",
    "        assert 5*6 == 30 \n",
    " \n",
    "    def test_strings_b_2(self):\n",
    "        print \"test b*2\"\n",
    "        assert 'b'*2 == 'bb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/written-in-code/testing-anti-patterns-b5ffc1612b8b\n",
    "* https://semaphoreci.com/community/tutorials/mocks-and-monkeypatching-in-python\n",
    "* https://holgerkrekel.net/2009/03/03/monkeypatching-in-unit-tests-done-right/\n",
    "* https://habrahabr.ru/post/269759/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mock is a simplification, don't rely on them heavily\n",
    "* classic fixtures are (more or less) anti-pattern, beacause of visibility and atomicity issues\n",
    "* monkey patch only if there no other way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Integration is a software development practice where members of a team integrate their work frequently, usually each person integrates at least daily - leading to multiple integrations per day. Each integration is verified by an automated build (including test) to detect integration errors as quickly as possible. Many teams find that this approach leads to significantly reduced integration problems and allows a team to develop cohesive software more rapidly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ci](http://www.anarsolutions.com/wp-content/uploads/2017/07/CI-in-devOps.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- job:\n",
    "    name: ui\n",
    "    scm:\n",
    "        - git-ui\n",
    "    auth-token: SeN6UttXbQxLym3Y\n",
    "\n",
    "    wrappers:\n",
    "      - timestamps\n",
    "\n",
    "    triggers:\n",
    "        - pollscm: \n",
    "            cron: \"* * * * *\"\n",
    "\n",
    "    publishers:\n",
    "        - junit:\n",
    "            results: reports/*.xml\n",
    "        - archive:\n",
    "            artifacts: 'deploy.xml,rpm/*/*/*.rpm'\n",
    "            allow-empty: 'true'\n",
    "        - xml-summary:\n",
    "            files: 'deploy.xml'\n",
    "        - mail-custom-on-fail:\n",
    "            recipients: 'me@.mail.ru'\n",
    "\n",
    "    builders:\n",
    "        - shell: rm -rf reports/*.xml\n",
    "        - deploy_ui:\n",
    "        - shell: docker pull docker.registry.mail.ru/ui\n",
    "        - shell: ./src/ui/ci/jenkins.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "cd `dirname $0`\n",
    "cd ../rbui/\n",
    "DJANGO_ENV=TEST python manage.py test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cd](https://qph.ec.quoracdn.net/main-qimg-a82fe747cc53bd5dadb0ccee0f02af5c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous delivery is an extension of continuous integration. It focuses on automating the software delivery process so that teams can easily and confidently deploy their code to production at any time. Continuous delivery leans heavily on deployment pipelines to automate the testing and deployment processes. A deployment pipeline is an automated system that runs increasingly rigorous test suites against a build as a series of sequential stages. This picks up where continuous integration leaves off, so a reliable continuous integration setup is a prerequisite to implementing continuous delivery.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous deployment is an extension of continuous delivery that automatically deploys each build that passes the full test cycle. Instead of waiting for a human gatekeeper to decide what and when to deploy to production, a continuous deployment system deploys everything that has successfully traversed the deployment pipeline. Keep in mind that while new code is automatically deployed, techniques exist to activate new features at a later time or for a subset of users. Deploying automatically pushes features and fixes to customers quickly, encourages smaller changes with limited scope, and helps avoid confusion over what is currently deployed to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.digitalocean.com/community/tutorials/an-introduction-to-continuous-integration-delivery-and-deployment\n",
    "* https://martinfowler.com/articles/continuousIntegration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CI/CD techniques could help scale development process but requries alot of preparation beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ff](http://blog.launchdarkly.com/wp-content/uploads/2015/10/ld_overview2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canary deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![canary](https://3.bp.blogspot.com/-CS3VvTXyq38/VrOvSX6ga5I/AAAAAAAAFj8/dcQUTRYme_8/s1600/Screen%2BShot%2B2016-02-03%2Bat%2B10.17.44%2BAM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![canary](https://martinfowler.com/bliki/images/canaryRelease/facebook-canary-strategy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Staged rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sr](https://cdn-images-1.medium.com/max/1600/1*Zi-tRLxtsRmPs1OFm7G7ig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://habrahabr.ru/post/168031/\n",
    "* http://muratbuffalo.blogspot.ru/2016/02/holistic-configuration-management-at.html\n",
    "* https://ieondemand.com/presentations/cloud-native-hadoop-at-netflix\n",
    "* https://martinfowler.com/bliki/CanaryRelease.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
