{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #5. Automatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. [Motivation](#Motivation)\n",
    "1. [Networking](#Networking)\n",
    "    1. [socket](#socket)\n",
    "    2. [TCP](#TCP)\n",
    "    3. [UDP](#UDP)\n",
    "    4. [HTTP](#HTTP)\n",
    "    5. [web-servers](#web-servers)\n",
    "2. [Databases](#Databases)\n",
    "    1. [DB API](#DB-API)\n",
    "    2. [Libraries](#Libraries)\n",
    "    3. [ping-reconnect](#ping-reconnect)\n",
    "    4. [Timeouts and retries](#Timeouts-and-retries)\n",
    "    5. [Slow quries](#Slow-quries)\n",
    "    6. [SQL-injections](#SQL-injections)\n",
    "    7. [Concurrent access](#Concurrent-access)\n",
    "    8. [Connection pool](#Connection-pool)\n",
    "    9. [Caching](#Caching)\n",
    "3. [Daemons](#Daemons)\n",
    "    1. [Daemonization](#Daemonization)\n",
    "    2. [Config](#Config)\n",
    "    3. [Logging](#Logging)\n",
    "4. [Deployment](#Deployment)\n",
    "    1. [Python-only](#Python-only)\n",
    "    2. [Linux distribution](#Linux-distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получить знания об особенносятх сетевого взаимодейстия, изучить нюансы общения со сторонними сервисами и создания собственных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Homework__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "class Connection(object):\n",
    "    '''\\\n",
    "    Represents connection to the Tarantool server.\n",
    "\n",
    "    This class is responsible for connection and network exchange with the server.\n",
    "    Also this class provides low-level interface to data manipulation (insert/delete/update/select).\n",
    "    '''\n",
    "\n",
    "    def __init__(self, host, port,\n",
    "                 socket_timeout=SOCKET_TIMEOUT,\n",
    "                 reconnect_max_attempts=RECONNECT_MAX_ATTEMPTS,\n",
    "                 reconnect_delay=RECONNECT_DELAY,\n",
    "                 connect_now=True,\n",
    "                 schema = None):\n",
    "        '''\\\n",
    "        Initialize a connection to the server.\n",
    "\n",
    "        :param str host: Server hostname or IP-address\n",
    "        :param int port: Server port\n",
    "        :param bool connect_now: if True (default) than __init__() actually creates network connection.\n",
    "                             if False than you have to call connect() manualy.\n",
    "        :param schema: Data schema (see Developer guide and :class:`~tarantool.schema.Schema`)\n",
    "        :type schema: :class:`~tarantool.schema.Schema` or dict\n",
    "        '''\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.socket_timeout = socket_timeout\n",
    "        self.reconnect_delay = reconnect_delay\n",
    "        self.reconnect_max_attempts = reconnect_max_attempts\n",
    "        if isinstance(schema, Schema):\n",
    "            self.schema = schema\n",
    "        else:\n",
    "            self.schema = Schema(schema)\n",
    "        self._socket = None\n",
    "        if connect_now:\n",
    "            self.connect()\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        '''\\\n",
    "        Close connection to the server\n",
    "        '''\n",
    "        self._socket.close()\n",
    "        self._socket = None\n",
    "\n",
    "\n",
    "    def connect(self):\n",
    "        '''\\\n",
    "        Create connection to the host and port specified in __init__().\n",
    "        Usually there is no need to call this method directly,\n",
    "        since it is called when you create an `Connection` instance.\n",
    "\n",
    "        :raise: `NetworkError`\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            # If old socket already exists - close it and re-create\n",
    "            if self._socket:\n",
    "                self._socket.close()\n",
    "            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            self._socket.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n",
    "            self._socket.connect((self.host, self.port))\n",
    "            # It is important to set socket timeout *after* connection.\n",
    "            # Otherwise the timeout exception will rised, even if the server does not listen\n",
    "            self._socket.settimeout(self.socket_timeout)\n",
    "        except socket.error as e:\n",
    "            raise NetworkError(e)\n",
    "\n",
    "\n",
    "    def _read_response(self):\n",
    "        '''\n",
    "        Read response from the transport (socket)\n",
    "\n",
    "        :return: tuple of the form (header, body)\n",
    "        :rtype: tuple of two byte arrays\n",
    "        '''\n",
    "\n",
    "        buf = ''\n",
    "        l = 12\n",
    "\n",
    "        while 1:\n",
    "            r = self._socket.recv(l - len(buf))\n",
    "            if not r:\n",
    "                err = socket.error(\"Connection reset by peer\")\n",
    "                err.errno = errno.ECONNRESET\n",
    "                raise err\n",
    "            buf += r\n",
    "            if len(buf) < l:\n",
    "                continue\n",
    "\n",
    "            l = 12 + struct_L.unpack(buf[4:8])[0]\n",
    "\n",
    "            if len(buf) < l:\n",
    "                continue\n",
    "\n",
    "            return buf[0:12], buf[12:]\n",
    "\n",
    "        \n",
    "    def _send_request_wo_reconnect(self, request, space_name = None, field_defs = None, default_type = None):\n",
    "        '''\\\n",
    "        :rtype: `Response` instance\n",
    "\n",
    "        :raise: NetworkError\n",
    "        '''\n",
    "        assert isinstance(request, Request)\n",
    "\n",
    "        # Repeat request in a loop if the server returns completion_status == 1 (try again)\n",
    "        for attempt in xrange(RETRY_MAX_ATTEMPTS):    # pylint: disable=W0612\n",
    "            try:\n",
    "                self._socket.sendall(bytes(request))\n",
    "                header, body = self._read_response()\n",
    "                response = Response(self, header, body, space_name, field_defs, default_type)\n",
    "            except socket.error as e:\n",
    "                raise NetworkError(e)\n",
    "\n",
    "            if response.completion_status != 1:\n",
    "                return response\n",
    "            warn(response.return_message, RetryWarning)\n",
    "\n",
    "        # Raise an error if the maximum number of attempts have been made\n",
    "        raise DatabaseError(response.return_code, response.return_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Socket is not file object but makefile fixes it\n",
    "* It's easy to write programs that mysteriously \"freeze up\" or don't operate quite like you would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HTTPResponse:\n",
    "\n",
    "    # strict: If true, raise BadStatusLine if the status line can't be\n",
    "    # parsed as a valid HTTP/1.0 or 1.1 status line.  By default it is\n",
    "    # false because it prevents clients from talking to HTTP/0.9\n",
    "    # servers.  Note that a response with a sufficiently corrupted\n",
    "    # status line will look like an HTTP/0.9 response.\n",
    "\n",
    "    # See RFC 2616 sec 19.6 and RFC 1945 sec 6 for details.\n",
    "\n",
    "    def __init__(self, sock, debuglevel=0, strict=0, method=None, buffering=False):\n",
    "        if buffering:\n",
    "            # The caller won't be using any sock.recv() calls, so buffering\n",
    "            # is fine and recommended for performance.\n",
    "            self.fp = sock.makefile('rb')\n",
    "        else:\n",
    "            # The buffer size is specified as zero, because the headers of\n",
    "            # the response are read with readline().  If the reads were\n",
    "            # buffered the readline() calls could consume some of the\n",
    "            # response, which make be read via a recv() on the underlying\n",
    "            # socket.\n",
    "            self.fp = sock.makefile('rb', 0)\n",
    "        self.debuglevel = debuglevel\n",
    "        self.strict = strict\n",
    "        self._method = method\n",
    "\n",
    "        self.msg = None\n",
    "\n",
    "        # from the Status-Line of the response\n",
    "        self.version = _UNKNOWN # HTTP-Version\n",
    "        self.status = _UNKNOWN  # Status-Code\n",
    "        self.reason = _UNKNOWN  # Reason-Phrase\n",
    "\n",
    "        self.chunked = _UNKNOWN         # is \"chunked\" being used?\n",
    "        self.chunk_left = _UNKNOWN      # bytes left to read in current chunk\n",
    "        self.length = _UNKNOWN          # number of bytes left in response\n",
    "        self.will_close = _UNKNOWN      # conn will close at end of response\n",
    "\n",
    "    def _read_status(self):\n",
    "        # Initialize with Simple-Response defaults\n",
    "        line = self.fp.readline(_MAXLINE + 1)\n",
    "        if len(line) > _MAXLINE:\n",
    "            raise LineTooLong(\"header line\")\n",
    "        if self.debuglevel > 0:\n",
    "            print \"reply:\", repr(line)\n",
    "        if not line:\n",
    "            # Presumably, the server closed the connection before\n",
    "            # sending a valid response.\n",
    "            raise BadStatusLine(line)\n",
    "        try:\n",
    "            [version, status, reason] = line.split(None, 2)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                [version, status] = line.split(None, 1)\n",
    "                reason = \"\"\n",
    "            except ValueError:\n",
    "                # empty version will cause next test to fail and status\n",
    "                # will be treated as 0.9 response.\n",
    "                version = \"\"\n",
    "        if not version.startswith('HTTP/'):\n",
    "            if self.strict:\n",
    "                self.close()\n",
    "                raise BadStatusLine(line)\n",
    "            else:\n",
    "                # assume it's a Simple-Response from an 0.9 server\n",
    "                self.fp = LineAndFileWrapper(line, self.fp)\n",
    "                return \"HTTP/0.9\", 200, \"\"\n",
    "\n",
    "        # The status code is a three-digit number\n",
    "        try:\n",
    "            status = int(status)\n",
    "            if status < 100 or status > 999:\n",
    "                raise BadStatusLine(line)\n",
    "        except ValueError:\n",
    "            raise BadStatusLine(line)\n",
    "        return version, status, reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that reading/writing to a socket may involve partial data transfer\n",
    "* send() returns actual bytes sent\n",
    "    * you want to use s.sendall(data) - blocks until all is sent\n",
    "* recv() length is only a maximum limit\n",
    "    * will return empty string when connections has been closed\n",
    "* for TCP, the data stream is continuous - no concept of records, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> len(data)\n",
    "1000000\n",
    ">>> s.send(data)\n",
    "37722\n",
    ">>>\n",
    ">>> data = s.recv(10000)\n",
    ">>> len(data)\n",
    "6420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Client\n",
    "...\n",
    "s.send(data)\n",
    "s.send(moredata)\n",
    "...\n",
    "# Server\n",
    "...\n",
    "data = s.recv(maxsize) # This recv() may return data\n",
    "                       # from both of the sends\n",
    "                       # combined or less data than\n",
    "                       # even the first send"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### TCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tcp](http://www.tenouk.com/Module39_files/image007.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from socket import *\n",
    "s = socket(AF_INET,SOCK_STREAM)\n",
    "s.bind((\"\",9000))\n",
    "s.listen(5)\n",
    "while True:\n",
    "    c,a = s.accept()\n",
    "    print \"Received connection from\", a\n",
    "    c.send(\"Hello %s\\n\" % a[0])\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _eintr_retry(func, *args):\n",
    "    \"\"\"restart a system call interrupted by EINTR\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            return func(*args)\n",
    "        except (OSError, select.error) as e:\n",
    "            if e.args[0] != errno.EINTR:\n",
    "                raise\n",
    "\n",
    "                \n",
    "class BaseServer:\n",
    "    timeout = None\n",
    "    def __init__(self, server_address, RequestHandlerClass):\n",
    "        \"\"\"Constructor.  May be extended, do not override.\"\"\"\n",
    "        self.server_address = server_address\n",
    "        self.RequestHandlerClass = RequestHandlerClass\n",
    "        self.__is_shut_down = threading.Event()\n",
    "        self.__shutdown_request = False\n",
    "\n",
    "    def serve_forever(self, poll_interval=0.5):\n",
    "        \"\"\"Handle one request at a time until shutdown.\n",
    "        Polls for shutdown every poll_interval seconds. Ignores\n",
    "        self.timeout. If you need to do periodic tasks, do them in\n",
    "        another thread.\n",
    "        \"\"\"\n",
    "        self.__is_shut_down.clear()\n",
    "        try:\n",
    "            while not self.__shutdown_request:\n",
    "                # XXX: Consider using another file descriptor or\n",
    "                # connecting to the socket to wake this up instead of\n",
    "                # polling. Polling reduces our responsiveness to a\n",
    "                # shutdown request and wastes cpu at all other times.\n",
    "                r, w, e = _eintr_retry(select.select, [self], [], [],\n",
    "                                       poll_interval)\n",
    "                if self in r:\n",
    "                    self._handle_request_noblock()\n",
    "        finally:\n",
    "            self.__shutdown_request = False\n",
    "            self.__is_shut_down.set()\n",
    "\n",
    "    def shutdown(self):\n",
    "        \"\"\"Stops the serve_forever loop.\n",
    "        Blocks until the loop has finished. This must be called while\n",
    "        serve_forever() is running in another thread, or it will\n",
    "        deadlock.\n",
    "        \"\"\"\n",
    "        self.__shutdown_request = True\n",
    "        self.__is_shut_down.wait()\n",
    "\n",
    "    # The distinction between handling, getting, processing and\n",
    "    # finishing a request is fairly arbitrary.  Remember:\n",
    "    #\n",
    "    # - handle_request() is the top-level call.  It calls\n",
    "    #   select, get_request(), verify_request() and process_request()\n",
    "    # - get_request() is different for stream or datagram sockets\n",
    "    # - process_request() is the place that may fork a new process\n",
    "    #   or create a new thread to finish the request\n",
    "    # - finish_request() instantiates the request handler class;\n",
    "    #   this constructor will handle the request all by itself\n",
    "\n",
    "    def handle_request(self):\n",
    "        \"\"\"Handle one request, possibly blocking.\n",
    "        Respects self.timeout.\n",
    "        \"\"\"\n",
    "        # Support people who used socket.settimeout() to escape\n",
    "        # handle_request before self.timeout was available.\n",
    "        timeout = self.socket.gettimeout()\n",
    "        if timeout is None:\n",
    "            timeout = self.timeout\n",
    "        elif self.timeout is not None:\n",
    "            timeout = min(timeout, self.timeout)\n",
    "\n",
    "        # select.select(rlist, wlist, xlist[, timeout])\n",
    "        # rlist: wait until ready for reading\n",
    "        # wlist: wait until ready for writing\n",
    "        # xlist: wait for an “exceptional condition” \n",
    "        # (see the manual page for what your system considers such a condition)\n",
    "        fd_sets = _eintr_retry(select.select, [self], [], [], timeout)\n",
    "        # empty if timeout reached\n",
    "        if not fd_sets[0]:\n",
    "            self.handle_timeout()\n",
    "            return\n",
    "        self._handle_request_noblock()\n",
    "\n",
    "    def _handle_request_noblock(self):\n",
    "        \"\"\"Handle one request, without blocking.\n",
    "        I assume that select.select has returned that the socket is\n",
    "        readable before this function was called, so there should be\n",
    "        no risk of blocking in get_request().\n",
    "        \"\"\"\n",
    "        try:\n",
    "            request, client_address = self.get_request()\n",
    "        except socket.error:\n",
    "            return\n",
    "        if self.verify_request(request, client_address):\n",
    "            try:\n",
    "                self.process_request(request, client_address)\n",
    "            except:\n",
    "                self.handle_error(request, client_address)\n",
    "                self.shutdown_request(request)\n",
    "        else:\n",
    "            self.shutdown_request(request)\n",
    "\n",
    "    def process_request(self, request, client_address):\n",
    "        \"\"\"Call finish_request.\n",
    "        Overridden by ForkingMixIn and ThreadingMixIn.\n",
    "        \"\"\"\n",
    "        self.finish_request(request, client_address)\n",
    "        self.shutdown_request(request)\n",
    "\n",
    "    def finish_request(self, request, client_address):\n",
    "        \"\"\"Finish one request by instantiating RequestHandlerClass.\"\"\"\n",
    "        self.RequestHandlerClass(request, client_address, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCPServer(BaseServer):\n",
    "    address_family = socket.AF_INET\n",
    "    socket_type = socket.SOCK_STREAM\n",
    "    request_queue_size = 5\n",
    "    allow_reuse_address = False\n",
    "\n",
    "    def __init__(self, server_address, RequestHandlerClass, bind_and_activate=True):\n",
    "        \"\"\"Constructor.  May be extended, do not override.\"\"\"\n",
    "        BaseServer.__init__(self, server_address, RequestHandlerClass)\n",
    "        self.socket = socket.socket(self.address_family,\n",
    "                                    self.socket_type)\n",
    "        if bind_and_activate:\n",
    "            try:\n",
    "                self.server_bind()\n",
    "                self.server_activate()\n",
    "            except:\n",
    "                self.server_close()\n",
    "                raise\n",
    "\n",
    "    def server_bind(self):\n",
    "        \"\"\"Called by constructor to bind the socket.\n",
    "        May be overridden.\n",
    "        \"\"\"\n",
    "        if self.allow_reuse_address:\n",
    "            self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        self.socket.bind(self.server_address)\n",
    "        self.server_address = self.socket.getsockname()\n",
    "\n",
    "    def server_activate(self):\n",
    "        \"\"\"Called by constructor to activate the server.\n",
    "        May be overridden.\n",
    "        \"\"\"\n",
    "        self.socket.listen(self.request_queue_size)\n",
    "\n",
    "    def server_close(self):\n",
    "        \"\"\"Called to clean-up the server.\n",
    "        May be overridden.\n",
    "        \"\"\"\n",
    "        self.socket.close()\n",
    "\n",
    "    def fileno(self):\n",
    "        \"\"\"Return socket file number.\n",
    "        Interface required by select().\n",
    "        \"\"\"\n",
    "        return self.socket.fileno()\n",
    "\n",
    "    def get_request(self):\n",
    "        \"\"\"Get the request and client address from the socket.\n",
    "        May be overridden.\n",
    "        \"\"\"\n",
    "        return self.socket.accept()\n",
    "\n",
    "    def shutdown_request(self, request):\n",
    "        \"\"\"Called to shutdown and close an individual request.\"\"\"\n",
    "        try:\n",
    "            #explicitly shutdown.  socket.close() merely releases\n",
    "            #the socket and waits for GC to perform the actual close.\n",
    "            request.shutdown(socket.SHUT_WR)\n",
    "        except socket.error:\n",
    "            pass #some platforms may raise ENOTCONN here\n",
    "        self.close_request(request)\n",
    "\n",
    "    def close_request(self, request):\n",
    "        \"\"\"Called to clean up an individual request.\"\"\"\n",
    "        request.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### UDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![udp](http://www.tenouk.com/Module39_files/image008.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple server\n",
    "from socket import *\n",
    "s = socket(AF_INET,SOCK_DGRAM)\n",
    "s.bind((\"\",10000))\n",
    "while True:\n",
    "    data, addr = s.recvfrom(maxsize)\n",
    "    resp = \"Get off my lawn!\"\n",
    "    s.sendto(resp,addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple client\n",
    "from socket import *\n",
    "s = socket(AF_INET,SOCK_DGRAM)\n",
    "msg = \"Hello World\"\n",
    "s.sendto(msg,(\"server.com\",10000))\n",
    "data, addr = s.recvfrom(maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UDPServer(TCPServer):\n",
    "\n",
    "    \"\"\"UDP server class.\"\"\"\n",
    "\n",
    "    allow_reuse_address = False\n",
    "\n",
    "    socket_type = socket.SOCK_DGRAM\n",
    "\n",
    "    max_packet_size = 8192\n",
    "\n",
    "    def get_request(self):\n",
    "        data, client_addr = self.socket.recvfrom(self.max_packet_size)\n",
    "        return (data, self.socket), client_addr\n",
    "\n",
    "    def server_activate(self):\n",
    "        # No need to call listen() for UDP.\n",
    "        pass\n",
    "\n",
    "    def shutdown_request(self, request):\n",
    "        # No need to shutdown anything.\n",
    "        self.close_request(request)\n",
    "\n",
    "    def close_request(self, request):\n",
    "        # No need to close anything.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HTTPFS(object):\n",
    "    def __init__(self, config):\n",
    "        self.httfs_base_url = config[\"HTTPFS\"]\n",
    "\n",
    "    def download(self, f, path, timeout=60):\n",
    "        url = urlparse.urljoin(self.httfs_base_url, f[\"path\"].lstrip(\"/\") + \"?op=OPEN\")\n",
    "        logging.info(\"Requesting %s\" % url)\n",
    "        request = urllib2.urlopen(url, timeout=timeout)\n",
    "        headers = request.info()\n",
    "        size = -1\n",
    "        if \"content-length\" in headers:\n",
    "            size = int(headers[\"content-length\"])\n",
    "        chunk_size = 1024 * 1024\n",
    "        read = 0\n",
    "        with open(path, \"w\") as fp:\n",
    "            while True:\n",
    "                chunk = request.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                fp.write(chunk)\n",
    "                read += len(chunk)\n",
    "        if size > 0 and read < size:\n",
    "            raise ValueError(\"Retrieval incomplete: got only %s out of %s bytes\" % (read, size))\n",
    "\n",
    "    def query(self, url, timeout=10):\n",
    "        max_retries = 3\n",
    "        err = Exception(\"Max retries exceeded\")\n",
    "        logging.info(\"Requesting %s\" % url)\n",
    "        for _ in xrange(max_retries):\n",
    "            try:\n",
    "                return urllib2.urlopen(url, timeout=timeout).read()\n",
    "            except urllib2.URLError as err:\n",
    "                if err.errno in (errno.ETIMEDOUT, socket.EAI_NONAME):\n",
    "                    continue\n",
    "                raise\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "fields = {\n",
    " 'txtUsername' : 'dave',\n",
    " 'txtPassword' : '12345',\n",
    " 'submit_login' : 'Log In'\n",
    "}\n",
    "opener = urllib2.build_opener(\n",
    "    urllib2.HTTPCookieProcessor()\n",
    ")\n",
    "request = urllib2.Request(\n",
    "    \"http://somedomain.com/login.asp\",\n",
    "     urllib.urlencode(fields)\n",
    ")\n",
    "# Login\n",
    "u = opener.open(request)\n",
    "resp = u.read()\n",
    "# Get a page, but use cookies returned by initial login\n",
    "u = opener.open(\"http://somedomain.com/private.asp\")\n",
    "resp = u.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Storage(object):\n",
    "    def __init__(self, host_port, conn_timeout=None, read_timeout=None, api_access=None):\n",
    "        self.host_port = host_port\n",
    "        self.session = requests.Session()\n",
    "        self.session.mount(\"http://\", requests.adapters.HTTPAdapter(max_retries=3))\n",
    "        if api_access:\n",
    "            self.session.headers.update({\"Authorization\": \"ApiKey %s:%s\" % api_access})\n",
    "        self.timeout = (conn_timeout or CONN_TIMEOUT, read_timeout or READ_TIMEOUT)\n",
    "\n",
    "    def send(self, request, **kwargs):\n",
    "        response = self.session.send(request.prepare(), timeout=self.timeout, **kwargs)\n",
    "        response.raise_for_status()\n",
    "        return response\n",
    "\n",
    "    def get(self, url):\n",
    "        request = requests.Request(\"GET\", url)\n",
    "        response = self.send(request, stream=True)\n",
    "        return response.raw\n",
    "\n",
    "    def head(self, url):\n",
    "        request = requests.Request(\"HEAD\", url)\n",
    "        try:\n",
    "            response = self.send(request)\n",
    "        except requests.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                return None\n",
    "            else:\n",
    "                raise e\n",
    "        return response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### web-servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Threading\n",
    "* Forking\n",
    "* Event-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "import threading\n",
    "\n",
    "bind_ip = '0.0.0.0'\n",
    "bind_port = 9999\n",
    "\n",
    "server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server.bind((bind_ip, bind_port))\n",
    "server.listen(5)  # max backlog of connections\n",
    "\n",
    "print 'Listening on {}:{}'.format(bind_ip, bind_port)\n",
    "\n",
    "\n",
    "def handle_client_connection(client_socket):\n",
    "    request = client_socket.recv(1024)\n",
    "    print 'Received {}'.format(request)\n",
    "    client_socket.send('ACK!')\n",
    "    client_socket.close()\n",
    "\n",
    "while True:\n",
    "    client_sock, address = server.accept()\n",
    "    print 'Accepted connection from {}:{}'.format(address[0], address[1])\n",
    "    client_handler = threading.Thread(\n",
    "        target=handle_client_connection,\n",
    "        args=(client_sock,)  # without comma you'd get a... TypeError: handle_client_connection() argument after * must be a sequence, not _socketobject\n",
    "    )\n",
    "    client_handler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![thread](http://berb.github.io/diploma-thesis/original/resources/mt-server.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![forking](http://berb.github.io/diploma-thesis/original/resources/mp-server.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![event](http://berb.github.io/diploma-thesis/original/resources/ev-server.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nginx](http://www.aosabook.org/images/nginx/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://www.apress.com/us/book/9781430230038\n",
    "* http://www.dabeaz.com/python/PythonNetBinder.pdf\n",
    "* http://www.tenouk.com/Module39a.html\n",
    "* https://docs.python.org/2.7/howto/sockets.html\n",
    "* https://hpbn.co/\n",
    "* http://berb.github.io/diploma-thesis/original/042_serverarch.html\n",
    "* https://www.ulduzsoft.com/2014/01/select-poll-epoll-practical-difference-for-system-architects/\n",
    "* http://www.aosabook.org/en/nginx.html\n",
    "* https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/\n",
    "* https://www.youtube.com/watch?v=aE0yawwB6h4\n",
    "* http://www.kegel.com/c10k.html\n",
    "* https://www.slideshare.net/joshzhu/nginx-internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sockets are almost file-like, but it's get tricky fast\n",
    "* TCP is reliable stream-oriented protocol\n",
    "* UDP is unrealiable packet-oriented protocol. Faster than TCP though\n",
    "* Always use timeouts and retries\n",
    "* requests is handy but devil in the details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a standard interface for Python database access modules. It’s documented in PEP 249. Nearly all Python database modules conform to this interface\n",
    "* MySQL\n",
    "* PostgreSQL\n",
    "* SQL Server\n",
    "* Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version : 5.6.20 \n",
      "[{'rID': 201L, 'name': u'Sarah Martinez'}, {'rID': 202L, 'name': u'Daniel Lewis'}, {'rID': 203L, 'name': u'Brittany Harris'}, {'rID': 204L, 'name': u'Mike Anderson'}, {'rID': 205L, 'name': u'Chris Jackson'}, {'rID': 206L, 'name': u'Elizabeth Thomas'}, {'rID': 207L, 'name': u'James Cameron'}, {'rID': 208L, 'name': u'Ashley White'}]\n"
     ]
    }
   ],
   "source": [
    "import MySQLdb\n",
    "\n",
    "def dictfetchall(cursor):\n",
    "    \"Return all rows from a cursor as a dict\"\n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    return [\n",
    "        dict(zip(columns, row))\n",
    "        for row in cursor.fetchall()\n",
    "    ]\n",
    "\n",
    "\n",
    "db = MySQLdb.connect(host=\"localhost\",user=\"root\", db=\"imdb\", charset=\"utf8\")\n",
    "cursor = db.cursor() # represent a database cursor, which is used to manage the context of a fetch operation. \n",
    "cursor.execute(\"SELECT VERSION()\")\n",
    "data = cursor.fetchone()\n",
    "print \"Database version : %s \" % data\n",
    "cursor.execute(\"SELECT * FROM Reviewer\")\n",
    "print dictfetchall(cursor)\n",
    "cursor.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SELECT `t1`.`mID`, `t1`.`rID`, `t1`.`stars`, `t1`.`ratingDate` FROM `rating` AS t1 INNER JOIN `reviewer` AS t2 ON (`t2`.`rID` = `t1`.`rID`) INNER JOIN `movie` AS t3 ON (`t3`.`mID` = `t1`.`mID`) WHERE (`t1`.`stars` >= %s)', [4])\n",
      "101\n",
      "106\n",
      "108\n",
      "108\n",
      "106\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "import peewee\n",
    "\n",
    "database = peewee.MySQLDatabase(\"imdb\", host=\"localhost\",user=\"root\", charset=\"utf8\")\n",
    "class BaseModel(peewee.Model):\n",
    "    class Meta:\n",
    "        database = database\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    mid = peewee.IntegerField(db_column=\"mID\")\n",
    "    title = peewee.TextField()\n",
    "    year = peewee.IntegerField()\n",
    "    director = peewee.TextField()\n",
    "\n",
    "class Rating(BaseModel):\n",
    "    mid = peewee.IntegerField(db_column=\"mID\")\n",
    "    rid = peewee.IntegerField(db_column=\"rID\")\n",
    "    stars = peewee.IntegerField()\n",
    "    date = peewee.DateField(db_column=\"ratingDate\")\n",
    "    \n",
    "    class Meta:\n",
    "        primary_key = peewee.CompositeKey('mid', 'rid')\n",
    "\n",
    "class Reviewer(BaseModel):\n",
    "    rid = peewee.IntegerField(db_column=\"rID\")\n",
    "    name = peewee.TextField()\n",
    "\n",
    "q = Rating.select() \\\n",
    "    .join(Reviewer, on=(Reviewer.rid == Rating.rid)) \\\n",
    "    .join(Movie, on=(Movie.mid == Rating.mid)) \\\n",
    "    .where(Rating.stars >= 4)\n",
    "\n",
    "print q.sql()\n",
    "for r  in q:\n",
    "    print r.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camembert\n",
      "Red Leicester\n",
      "Camembert\n",
      "Red Leicester\n",
      "Camembert\n",
      "Red Leicester\n",
      "Camembert\n",
      "Red Leicester\n",
      "\n",
      "Camembert 2\n",
      "Red Leicester 1\n",
      "Camembert 2\n",
      "Red Leicester 1\n",
      "Camembert 2\n",
      "Red Leicester 1\n",
      "Camembert 2\n",
      "Red Leicester 1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pony import orm\n",
    "\n",
    "db = orm.Database()\n",
    "db.bind(provider='mysql', user='root', host='localhost', db='test')\n",
    "\n",
    "class Cheese(db.Entity):\n",
    "    type = orm.Required(str)\n",
    "    purchases = orm.Set(lambda: Purchase)\n",
    "\n",
    "class Customer(db.Entity):\n",
    "    name = orm.Required(str)\n",
    "    purchases = orm.Set(lambda: Purchase)\n",
    "\n",
    "class Purchase(db.Entity):\n",
    "    date = orm.Required(datetime.date)\n",
    "    customer = orm.Required(Customer)\n",
    "    cheeses = orm.Set(Cheese)\n",
    "\n",
    "db.generate_mapping(create_tables=True)\n",
    "\n",
    "camembert = Cheese(type='Camembert')\n",
    "leicester = Cheese(type='Red Leicester')\n",
    "cat = Customer(name='Cat')\n",
    "doug = Customer(name='Douglas')\n",
    "d = datetime.date(1971, 12, 18)\n",
    "day = datetime.timedelta(1)\n",
    "Purchase(date=(d - 1 * day), customer=doug, cheeses={camembert, leicester})\n",
    "Purchase(date=d, customer=cat, cheeses={camembert})\n",
    "orm.commit()\n",
    "\n",
    "yesterday = d - 2 * day \n",
    "for cheese in (\n",
    "        orm.select(p.cheeses for p in Purchase if p.date > yesterday)\n",
    "    ):\n",
    "    print(cheese.type)\n",
    "print\n",
    "\n",
    "for cheese, purchase_count in (\n",
    "        orm.left_join((c, orm.count(p))\n",
    "        for c in Cheese\n",
    "        for p in c.purchases)\n",
    "    ):\n",
    "    print cheese.type, purchase_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ping-reconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': u'Sarah Martinez', 'rID': 201L}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import closing\n",
    "\n",
    "class Database(object):\n",
    "    conn = None\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.host = config.get('host')\n",
    "        self.user = config.get('user')\n",
    "        self.password = config.get('password')\n",
    "        self.database = config.get('database')\n",
    "\n",
    "    def connect(self):\n",
    "        self.conn = MySQLdb.connect(host=self.host, user=self.user, db=self.database, charset='utf8')\n",
    "        self.conn.autocommit(True)  # for InnoDB\n",
    "\n",
    "    def query(self, sql):\n",
    "        try:\n",
    "            self.conn.ping()\n",
    "        except:\n",
    "            self.connect()\n",
    "        with closing(self.conn.cursor()) as cursor:\n",
    "            cursor.execute(sql)\n",
    "            return self.dictfetchall(cursor)\n",
    "\n",
    "    @staticmethod\n",
    "    def dictfetchall(cursor):\n",
    "        \"Returns all rows from a cursor as a dict\"\n",
    "        desc = cursor.description\n",
    "        return [\n",
    "            dict(zip([col[0] for col in desc], row))\n",
    "            for row in cursor.fetchall()\n",
    "        ]\n",
    "\n",
    "db = Database({\"host\": \"localhost\", \"user\": \"root\", \"database\": \"imdb\"})\n",
    "like = \"S\"\n",
    "db.query(\"SELECT * FROM Reviewer Where name LIKE '%s%%'\" % like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL-injections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sqlinj](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': u'Sarah Martinez', 'rID': 201L}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextlib import closing\n",
    "\n",
    "class Database(object):\n",
    "    conn = None\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.host = config.get('host')\n",
    "        self.user = config.get('user')\n",
    "        self.password = config.get('password')\n",
    "        self.database = config.get('database')\n",
    "\n",
    "    def connect(self):\n",
    "        self.conn = MySQLdb.connect(host=self.host, user=self.user, db=self.database, charset='utf8')\n",
    "        self.conn.autocommit(True)  # for InnoDB\n",
    "\n",
    "    def query(self, sql, params=()):\n",
    "        try:\n",
    "            self.conn.ping()\n",
    "        except:\n",
    "            self.connect()\n",
    "        with closing(self.conn.cursor()) as cursor:\n",
    "            cursor.execute(sql, params)\n",
    "            return self.dictfetchall(cursor)\n",
    "\n",
    "    @staticmethod\n",
    "    def dictfetchall(cursor):\n",
    "        \"Returns all rows from a cursor as a dict\"\n",
    "        desc = cursor.description\n",
    "        return [\n",
    "            dict(zip([col[0] for col in desc], row))\n",
    "            for row in cursor.fetchall()\n",
    "        ]\n",
    "\n",
    "\n",
    "db = Database({\"host\": \"localhost\", \"user\": \"root\", \"database\": \"imdb\"})\n",
    "like = \"S%\"\n",
    "db.query(\"SELECT * FROM Reviewer Where name LIKE %s\", (like,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeouts and retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing\n",
    "\n",
    "class Database(object):\n",
    "    conn = None\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.host = config.get('host')\n",
    "        self.user = config.get('user')\n",
    "        self.password = config.get('password')\n",
    "        self.database = config.get('database')\n",
    "\n",
    "    def connect(self):\n",
    "        self.conn = MySQLdb.connect(\n",
    "            host=self.host,\n",
    "            user=self.user,\n",
    "            db=self.database,\n",
    "            connect_timeout=5,\n",
    "            charset='utf8'\n",
    "        )\n",
    "        self.conn.autocommit(True)  # for InnoDB\n",
    "\n",
    "    def query(self, sql, params=()):\n",
    "        try:\n",
    "            self.conn.ping()\n",
    "        except:\n",
    "            self.connect()\n",
    "        with closing(self.conn.cursor()) as cursor:\n",
    "            cursor.execute(sql, params)\n",
    "            return self.dictfetchall(cursor)\n",
    "\n",
    "    @staticmethod\n",
    "    def dictfetchall(cursor):\n",
    "        \"Returns all rows from a cursor as a dict\"\n",
    "        desc = cursor.description\n",
    "        return [\n",
    "            dict(zip([col[0] for col in desc], row))\n",
    "            for row in cursor.fetchall()\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClientTarantool(object):\n",
    "    def __init__(self, host, port):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self._conns = []\n",
    "        self._conns.append(self.get_conn())\n",
    "\n",
    "    def get_conn(self):\n",
    "        if not self._conns:\n",
    "            while True:\n",
    "                try:\n",
    "                    return tarantool.Connection(host=self.host, port=self.port,\n",
    "                                                reconnect_delay=0.01, socket_timeout=5)\n",
    "                except Exception, e:\n",
    "                    msg = \"Cannot connect to Clients tarantool: %s\" % e\n",
    "                    print msg  # will show up at uwsgi log\n",
    "                    logging.critical(msg)\n",
    "                    time.sleep(1)\n",
    "        else:\n",
    "            return self._conns.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _send_request(self, request, space_name = None, field_defs = None, default_type = None):\n",
    "    '''\\\n",
    "    Send the request to the server through the socket.\n",
    "    Return an instance of `Response` class.\n",
    "\n",
    "    :param request: object representing a request\n",
    "    :type request: `Request` instance\n",
    "\n",
    "    :rtype: `Response` instance\n",
    "    '''\n",
    "    assert isinstance(request, Request)\n",
    "\n",
    "    connected = True\n",
    "    attempt = 1\n",
    "    while True:\n",
    "        try:\n",
    "            if not connected:\n",
    "                time.sleep(self.reconnect_delay)\n",
    "                self.connect()\n",
    "                connected = True\n",
    "                warn(\"Successfully reconnected\", NetworkWarning)\n",
    "            response = self._send_request_wo_reconnect(request, space_name, field_defs, default_type)\n",
    "            break\n",
    "        except NetworkError as e:\n",
    "            if attempt > self.reconnect_max_attempts:\n",
    "                raise\n",
    "            warn(\"%s : Reconnect to %s:%s attempt %d of %d\" % (e.message, self.host, self.port,\n",
    "                 attempt, self.reconnect_max_attempts), NetworkWarning)\n",
    "            attempt += 1\n",
    "            connected = False\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TarantoolMemcache(object):\n",
    "\n",
    "    def __init__(self, host_port, max_retries=float('inf'), silent=False):\n",
    "        import memcache\n",
    "        memcache.SERVER_MAX_KEY_LENGTH = 1000\n",
    "        self._client = memcache.Client([host_port])\n",
    "        self._srv = self._client.servers[0]\n",
    "        self.max_retries = max_retries\n",
    "        self.silent = silent\n",
    "\n",
    "    def _reconnect_wrapper(self, func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            while self.max_retries:\n",
    "                ret = func(*args, **kwargs)\n",
    "\n",
    "                if not self._srv._check_dead():\n",
    "                    return ret\n",
    "\n",
    "                if not self.silent:\n",
    "                    logging.warning(\"Tarantool %s:%s is dead. Reconnect in 1 sec\" % self._srv.address)\n",
    "                time.sleep(1)\n",
    "                self._client.forget_dead_hosts()\n",
    "                # there is a typo in python-memcached-1.43-6.el6.noarch so `forget_dead_hosts` wont work\n",
    "                self._srv.deaduntil = 0\n",
    "                self.max_retries -= 1\n",
    "            else:\n",
    "                raise TarantoolException(\"Failed to execute request\")\n",
    "        return wrapper\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        a = getattr(self._client, attr)\n",
    "        if attr in (\"get\", \"get_multi\", \"set\", \"set_multi\", \"delete\", \"delete_multi\", \"add\"):\n",
    "            return self._reconnect_wrapper(a)\n",
    "        return a\n",
    "\n",
    "    def __del__(self, *args, **kwargs):\n",
    "        try:\n",
    "            self._client.disconnect_all()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slow quries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected with id 54\n",
      "Killing 54\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(2013, 'Lost connection to MySQL server during query')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-a2e16196ad27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"root\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"database\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"imdb\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT SLEEP(5)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-a2e16196ad27>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mkill_query_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (2013, 'Lost connection to MySQL server during query')"
     ]
    }
   ],
   "source": [
    "from contextlib import closing\n",
    "import threading\n",
    "\n",
    "class Database(object):\n",
    "    conn = None\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.host = config.get('host')\n",
    "        self.user = config.get('user')\n",
    "        self.password = config.get('password')\n",
    "        self.database = config.get('database')\n",
    "        self.query_timeout = config.get('timeout', 2)\n",
    "\n",
    "    def get_connection(self):\n",
    "        return MySQLdb.connect(\n",
    "            host=self.host,\n",
    "            user=self.user,\n",
    "            db=self.database,\n",
    "            connect_timeout=5,\n",
    "            charset='utf8'\n",
    "        )\n",
    "        \n",
    "    def connect(self):\n",
    "        self.conn = self.get_connection()\n",
    "        self.conn.autocommit(True)  # for InnoDB\n",
    "        with closing(self.conn.cursor()) as cursor:\n",
    "            cursor.execute(\"SELECT CONNECTION_ID()\")\n",
    "            self.conn.id = cursor.fetchone()[0]\n",
    "        print \"Successfully connected with id %s\" % self.conn.id\n",
    "\n",
    "    def _harakiri(self, conn_id):\n",
    "        # could also use thread.interrupt_main() or os._exit(1)\n",
    "        conn = self.get_connection()\n",
    "        print \"Killing %s\" % conn_id\n",
    "        with closing(conn.cursor()) as cursor:\n",
    "            cursor.execute(\"KILL CONNECTION %s\", (conn_id,))\n",
    "        conn.close()\n",
    "        \n",
    "    def query(self, sql, params=()):\n",
    "        try:\n",
    "            self.conn.ping()\n",
    "        except:\n",
    "            self.connect()\n",
    "\n",
    "        kill_query_timer = threading.Timer(self.query_timeout, self._harakiri, args=(self.conn.id,))\n",
    "        kill_query_timer.start()\n",
    "        try:\n",
    "            with closing(self.conn.cursor()) as cursor:\n",
    "                cursor.execute(sql, params)\n",
    "                return self.dictfetchall(cursor)\n",
    "        except Exception, e:\n",
    "            raise e\n",
    "        finally:\n",
    "            kill_query_timer.cancel()\n",
    "\n",
    "    @staticmethod\n",
    "    def dictfetchall(cursor):\n",
    "        \"Returns all rows from a cursor as a dict\"\n",
    "        desc = cursor.description\n",
    "        return [\n",
    "            dict(zip([col[0] for col in desc], row))\n",
    "            for row in cursor.fetchall()\n",
    "        ]\n",
    "\n",
    "db = Database({\"host\": \"localhost\", \"user\": \"root\", \"database\": \"imdb\"})\n",
    "db.query(\"SELECT SLEEP(5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concurrent access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_LOCK = threading.Lock()\n",
    "\n",
    "def send_heartbeat(host):\n",
    "    update_query = \"\"\"\n",
    "        REPLACE INTO `servers`\n",
    "        SET `host` = %s, `heartbeat` = NOW()\n",
    "        \"\"\"\n",
    "    try:\n",
    "        with DB_LOCK:\n",
    "            lib.getdb('db').execute(update_query, host)\n",
    "    except Exception, e:\n",
    "        logging.warning(\"Cannot send heartbeat: %s\", repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import MySQLdb\n",
    "\n",
    "\n",
    "class DBThread(threading.Thread):\n",
    "    def __init__(self, conn, cur, name):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.conn = conn\n",
    "        self.cur = cur\n",
    "        self.name = name\n",
    "\n",
    "    def run(self): \n",
    "        insql = \"INSERT INTO cheese(type) VALUES (%s)\"\n",
    "        delsql = \"DELETE FROM cheese WHERE type=%s\"\n",
    "        self.cur.execute(insql, (self.name,))\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(delsql, (self.name,))\n",
    "        self.conn.commit()\n",
    "        self.cur.close()\n",
    "        self.conn.close()\n",
    "\n",
    "threads = []\n",
    "names = [\"cheese1\", \"cheese2\", \"cheese3\", \"cheese4\", \"cheese5\"]\n",
    "\n",
    "for name in names:\n",
    "    conn = MySQLdb.connect(host='localhost',user='root',db='test')\n",
    "    cur = conn.cursor()\n",
    "    t = DBThread(conn, cur, name)\n",
    "    threads.append(t)\n",
    "\n",
    "for th in threads:\n",
    "    th.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connection pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_connection_from_pool(key):\n",
    "    \"\"\"\n",
    "        First get from the queue with no wait\n",
    "    \"\"\"\n",
    "    q = _d_connection_queue.get(key)\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = q.get_nowait()\n",
    "    except Empty:\n",
    "        print \"Connections exhausted\"\n",
    "    if not connection:\n",
    "        if _get_connected_count(key) < _max_size:\n",
    "            print 'create extra connection less than max size'\n",
    "            connection = _create_new_connection_from_key(key)\n",
    "        else:\n",
    "            try:\n",
    "                connection = q.get(timeout=_max_wait_time)\n",
    "            except Empty:\n",
    "                print 'waiting connection timeout'\n",
    "    if connection:\n",
    "        _update_connected_count(key, 1)\n",
    "    return connection\n",
    "\n",
    "\n",
    "def _release_connection(key, connection):\n",
    "    if connection:\n",
    "        q = _d_connection_queue[key]\n",
    "        if _get_connected_count(key) > _max_size:\n",
    "            connection.close()\n",
    "        else:\n",
    "            q.put_nowait(connection)\n",
    "    _update_connected_count(key, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"There are 2 hard problems in computer science: cache invalidation, naming things, and off-by-1 errors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Calendar(object):\n",
    "    __calendar_cache = {'holidays': set(), 'unholidays': set(), 'timestamp': datetime.datetime.now() - datetime.timedelta(days=2)}\n",
    "    def __init__(self):\n",
    "        if datetime.datetime.now() - self.__calendar_cache['timestamp'] > datetime.timedelta(days=1):\n",
    "            sql = \"SELECT * FROM holidays_calendar\"\n",
    "            days = db.query(sql)\n",
    "            for day in days:\n",
    "                if day['is_holiday']:\n",
    "                    self.__calendar_cache['holidays'].add(day['date'])\n",
    "                else:\n",
    "                    self.__calendar_cache['unholidays'].add(day['date'])\n",
    "            self.__calendar_cache['timestamp'] = datetime.datetime.now()\n",
    "\n",
    "    def check_holiday(self, d):\n",
    "        if d not in self.__calendar_cache['unholidays']:\n",
    "            if d.weekday() in (5,6) or d in self.__calendar_cache['holidays']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def check_unholiday(self, d):\n",
    "        if d not in self.__calendar_cache['holidays']:\n",
    "            if d.weekday() not in (5,6) or d in self.__calendar_cache['unholidays']:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.python.org/dev/peps/pep-0249/\n",
    "* http://python-guide-pt-br.readthedocs.io/en/latest/scenarios/db/\n",
    "* http://docs.peewee-orm.com/en/latest/index.html\n",
    "* http://mysql-python.sourceforge.net/MySQLdb.html\n",
    "* https://docs.ponyorm.com/database.html\n",
    "* https://en.wikipedia.org/wiki/SQL_injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* know your database\n",
    "* know your database connector\n",
    "* beware of idle connections\n",
    "* timeout everything\n",
    "* don't use one connection from many threads without lock\n",
    "* use pooling to improve performance but don't leak connections\n",
    "* use caching to reduce load but don't forget to invalidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daemons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Daemonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "UMASK = 0\n",
    "WORKDIR = \"/\"\n",
    "MAXFD = 1024\n",
    "if (hasattr(os, \"devnull\")):\n",
    "    REDIRECT_TO = os.devnull\n",
    "else:\n",
    "    REDIRECT_TO = \"/dev/null\"\n",
    "\n",
    "def create_daemon():\n",
    "    try:\n",
    "        # 1. makes the shell think that the command is done\n",
    "        # 2. guaranteed that the child is not a process group leader for setsid\n",
    "        pid = os.fork()\n",
    "    except OSError, e:\n",
    "        raise Exception, \"%s [%d]\" % (e.strerror, e.errno)\n",
    "\n",
    "    if (pid == 0):\n",
    "        # 1. becomes a session leader of a new session\n",
    "        # 2. becomes the process group leader of a new process group\n",
    "        # 3. has no controlling terminal\n",
    "        os.setsid()\n",
    "        try:\n",
    "            # 1. makes second child orphaned - init process responsible for cleanup\n",
    "            # 2. no longer a session leader - prevents from acquiring a controlling terminal\n",
    "            pid = os.fork()\n",
    "        except OSError, e:\n",
    "            raise Exception, \"%s [%d]\" % (e.strerror, e.errno)\n",
    "\n",
    "        if (pid == 0):\n",
    "            os.chdir(WORKDIR)\n",
    "            os.umask(UMASK)\n",
    "        else:\n",
    "            os._exit(0)\n",
    "    else:\n",
    "        os._exit(0)\n",
    "\n",
    "    import resource\n",
    "    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]\n",
    "    if (maxfd == resource.RLIM_INFINITY):\n",
    "        maxfd = MAXFD\n",
    "  \n",
    "    for fd in range(0, maxfd):\n",
    "        try:\n",
    "            os.close(fd)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    os.open(REDIRECT_TO, os.O_RDWR)\n",
    "    os.dup2(0, 1)           # standard output (1)\n",
    "    os.dup2(0, 2)           # standard error (2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session (SID) → Process Group (PGID) → Process (PID)\n",
    "\n",
    "1. `Parent`    = PID: 28084, PGID: 28084, SID: 28046\n",
    "2. `Fork#1`    = PID: 28085, PGID: 28084, SID: 28046\n",
    "3. `Decouple#1`= PID: 28085, PGID: 28085, SID: 28085\n",
    "4. `Fork#2`    = PID: 28086, PGID: 28085, SID: 28085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    ". /etc/rc.d/init.d/functions\n",
    "\n",
    "pname=\"otusd\"\n",
    "exe=\"/usr/local/sbin/otusd.py\"\n",
    "pidfile=\"/var/run/${pname}.pid\"\n",
    "lockfile=\"/var/lock/${pname}\"\n",
    "\n",
    "[ -x $exe ] || exit 0\n",
    "\n",
    "RETVAL=0\n",
    "\n",
    "start() {\n",
    "    echo -n \"Starting $pname : \"\n",
    "    if [ -s ${pidfile} ]; then\n",
    "       RETVAL=1\n",
    "       echo -n \"Already running !\" && warning\n",
    "       echo\n",
    "    else\n",
    "       nohup ${exe} >/dev/null 2>&1 &\n",
    "       RETVAL=$?\n",
    "       PID=$!\n",
    "       [ $RETVAL -eq 0 ] && touch ${lockfile} && success || failure\n",
    "       echo\n",
    "       echo $PID > ${pidfile}\n",
    "    fi\n",
    "}\n",
    "\n",
    "stop() {\n",
    "    echo -n \"Shutting down $pname : \"\n",
    "    killproc ${exe}\n",
    "    RETVAL=$?\n",
    "    echo\n",
    "    if [ $RETVAL -eq 0 ]; then\n",
    "        rm -f ${lockfile}\n",
    "        rm -f ${pidfile}\n",
    "    fi\n",
    "}\n",
    "\n",
    "restart() {\n",
    "    echo -n \"Restarting $pname : \"\n",
    "    stop\n",
    "    sleep 2\n",
    "    start\n",
    "}\n",
    "\n",
    "\n",
    "status(){\n",
    "    kill -0 `cat ${pidfile} 2>/dev/null` &> /dev/null\n",
    "    RETVAL=$?\n",
    "    if [ $RETVAL -eq 0 ]; then\n",
    "        echo -e \"$pname is \\033[0;32mrunning\\033[0m\";\n",
    "    else\n",
    "        echo -e \"$pname is \\033[0;31mstopped\\033[0m\";\n",
    "    fi\n",
    "    return $RETVAL\n",
    "}\n",
    "\n",
    "case \"$1\" in\n",
    "    start)\n",
    "        start\n",
    "    ;;\n",
    "    stop)\n",
    "        stop\n",
    "    ;;\n",
    "    status)\n",
    "        status ${pname}\n",
    "    ;;\n",
    "    restart)\n",
    "        restart\n",
    "    ;;\n",
    "    *)\n",
    "        echo \"Usage: $0 {start|stop|status|restart}\"\n",
    "    ;; esac\n",
    "\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[Unit]\n",
    "Description=otus daemon example\n",
    "After=network.target\n",
    "\n",
    "[Service]\n",
    "Type=simple\n",
    "ExecStart=/usr/bin/python /usr/local/otus/otus.py\n",
    "Restart=always\n",
    "User=otus\n",
    "PIDFile=/var/run/otus.pid\n",
    "\n",
    "[Install]\n",
    "WantedBy=multi-user.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "mysql = {'host': 'localhost',\n",
    "         'user': 'root',\n",
    "         'passwd': 'my secret password',\n",
    "         'db': 'write-math'}\n",
    "use_anonymous = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import databaseconfig as cfg\n",
    "connect(cfg.mysql['host'], cfg.mysql['user'], cfg.mysql['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAML"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mysql:\n",
    "    host: localhost\n",
    "    user: root\n",
    "    passwd: my secret password\n",
    "    db: write-math\n",
    "other:\n",
    "    use_anonymous: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "\n",
    "for section in cfg:\n",
    "    print(section)\n",
    "print(cfg['mysql'])\n",
    "print(cfg['other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[mysql]\n",
    "host=localhost\n",
    "user=root\n",
    "passwd=my secret password\n",
    "db=write-math\n",
    "\n",
    "[other]\n",
    "use_anonymous=yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import ConfigParser\n",
    "import io\n",
    "\n",
    "# Load the configuration file\n",
    "with open(\"config.ini\") as f:\n",
    "    sample_config = f.read()\n",
    "config = ConfigParser.RawConfigParser(allow_no_value=True)\n",
    "config.readfp(io.BytesIO(sample_config))\n",
    "\n",
    "# List all contents\n",
    "print(\"List all contents\")\n",
    "for section in config.sections():\n",
    "    print(\"Section: %s\" % section)\n",
    "    for options in config.options(section):\n",
    "        print(\"x %s:::%s:::%s\" % (options,\n",
    "                                  config.get(section, options),\n",
    "                                  str(type(options))))\n",
    "\n",
    "# Print some contents\n",
    "print(\"\\nPrint some contents\")\n",
    "print(config.get('other', 'use_anonymous'))  # Just get the value\n",
    "print(config.getboolean('other', 'use_anonymous'))  # You know the datatype?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('config.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "DEFAULT = {\n",
    "    \"LOGFILE\": \"/var/log/vconverterd.log\",\n",
    "}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = optparse.OptionParser()\n",
    "    parser.add_option(\"--config\", dest='config_path', action='store', default=CONFIG_FILE)\n",
    "    (options, _args) = parser.parse_args()\n",
    "\n",
    "    config = lib.config_read(options.config_path, DEFAULT)\n",
    "    lib.logging_init(logfile)\n",
    "    logging.getLogger(\"requests\").setLevel(logging.ERROR)\n",
    "    try:\n",
    "        main(config)\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unhandled exception: %s\", repr(e))\n",
    "        raise\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info('KeyboardInterrupt.')\n",
    "    except SystemExit:\n",
    "        logging.info('SystemExit.')\n",
    "    finally:\n",
    "        logging.info(\"Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "from logging.handlers import WatchedFileHandler\n",
    "\n",
    "\n",
    "class LogFormatter(logging.Formatter):\n",
    "    level = 0\n",
    "\n",
    "    def format(self, record):\n",
    "        ret = \"[%s] %s %s\" % (\n",
    "            self.formatTime(record),\n",
    "            record.levelname[0].upper(),\n",
    "            record.getMessage()\n",
    "        )\n",
    "        if record.exc_info:\n",
    "            ret += \"\\n\" + self.formatException(record.exc_info)\n",
    "        return ret\n",
    "\n",
    "    def formatTime(self, record, datefmt=None):\n",
    "        d = datetime.datetime.fromtimestamp(record.created)\n",
    "        return \"%s\" % d.strftime(\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "def logging_init(logfile=None, level=logging.DEBUG, clear=True):\n",
    "    root = logging.getLogger()\n",
    "    root.setLevel(level)\n",
    "\n",
    "    if clear:\n",
    "        for hdlr in root.handlers:\n",
    "            root.removeHandler(hdlr)\n",
    "\n",
    "    if logfile is None:\n",
    "        hdlr = logging.StreamHandler()\n",
    "    else:\n",
    "        hdlr = WatchedFileHandler(logfile)\n",
    "\n",
    "    fmt = LogFormatter()\n",
    "    hdlr.setFormatter(fmt)\n",
    "    root.addHandler(hdlr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[23.07.2017 15:02:20] I Read: 165058758. In queue: 5 * 300\n",
    "[23.07.2017 15:02:22] I Waiting for queue to empty\n",
    "[23.07.2017 15:02:22] I Queue size: 5 * 300\n",
    "[23.07.2017 15:02:32] I 142549760 profiles processed, 142549760 refreshed\n",
    "[23.07.2017 15:02:32] I Exiting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://code.activestate.com/recipes/278731-creating-a-daemon-the-python-way/\n",
    "* http://www.gavinj.net/2012/06/building-python-daemon-process.html\n",
    "* https://habrahabr.ru/company/southbridge/blog/255845/\n",
    "* http://ptgmedia.pearsoncmg.com/images/9780321637734/samplepages/0321637739.pdf\n",
    "* http://www.gavinj.net/2012/06/building-python-daemon-process.html\n",
    "* https://martin-thoma.com/configuration-files-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* daemon is long-lived process running in a background\n",
    "* non-system daemon should have confing somwhere at /usr/local/etc\n",
    "* daemon should write logs in specified format somwhere to /var/log/daemon_name/daemon_name.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Python-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyPi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".\n",
    "|--- archive/\n",
    "     |--- MyPackage/\n",
    "          |--- MyPackage.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python -m SimpleHTTPServer 9000\n",
    "pip install --extra-index-url=http://127.0.0.1:9000/ MyPackage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wheels vs Eggs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linux distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* package management \n",
    "* fpm\n",
    "    * fpm -s python -t rpm pytz"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "License:        BSD\n",
    "Vendor:         s.stupnikov\n",
    "Group:          s.stupnikov\n",
    "URL:            https://github.com/s-stupnikov/\n",
    "Source0:        otus_example.tar.gz\n",
    "BuildRoot:      %{_tmppath}/otus_example\n",
    "Name:           otus_example\n",
    "Version:        0.0.1\n",
    "Release:        1\n",
    "Group:          System Environment/Libraries\n",
    "Requires:       python\n",
    "Requires:       python-requests\n",
    "Requires:       python-tarantool\n",
    "BuildArch:      noarch\n",
    "Summary:        Example for Otus.ru\n",
    "\n",
    "%description\n",
    "Example for Python Developer course at Otus.ru\n",
    "\n",
    "%define __bindir /usr/local/otus_example\n",
    "%define __etcdir /usr/local/etc\n",
    "\n",
    "%prep\n",
    "rm -rf %{buildroot}\n",
    "%setup -n otus_example\n",
    "\n",
    "%build\n",
    "touch path/inside/unpacked/archive/otus_example.conf\n",
    "\n",
    "%install\n",
    "[ \"%{buildroot}\" != \"/\" ] && rm -fr %{buildroot}\n",
    "%{__mkdir} -p %{buildroot}%{__bindir}\n",
    "%{__mkdir} -p %{buildroot}%{__etcdir}\n",
    "\n",
    "%{__install} -pD -m 755 path/inside/unpacked/archive/otus_example.py %{buildroot}/%{__bindir}/otus_example.py\n",
    "%{__install} -pD -m 644 path/inside/unpacked/archive/otus_example.conf %{buildroot}/%{__etcdir}/otus_example.conf\n",
    "\n",
    "%clean\n",
    "rm -rf $RPM_BUILD_ROOT\n",
    "\n",
    "%files\n",
    "%{__bindir}/*\n",
    "%config(noreplace) %{__etcdir}/*.conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executable ZIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ping!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    try:\n",
    "        print 'ping!'\n",
    "    except SyntaxError: # Python 3\n",
    "        print('ping!')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zip machine.zip __main__.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ python machine.zip\n",
    "ping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an executable file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ echo '#!/usr/bin/env python' > machine\n",
    "$ cat machine.zip >> machine\n",
    "$ chmod u+x machine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ ./machine\n",
    "ping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://packaging.python.org/tutorials/distributing-packages/\n",
    "* https://packaging.python.org/discussions/wheel-vs-egg/\n",
    "* https://code.tutsplus.com/tutorials/how-to-write-package-and-distribute-a-library-in-python--cms-28693"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use PyPI for libraries or Python-only distributions\n",
    "* use OS package management system for the “right way” to distribute code on Linux"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
